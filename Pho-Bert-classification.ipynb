{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8800059,"sourceType":"datasetVersion","datasetId":5291812}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch, os\nimport pandas as pd\nimport numpy as np\nfrom transformers import pipeline, BertForSequenceClassification, BertTokenizerFast\nfrom transformers import RobertaForSequenceClassification, AutoTokenizer\nfrom torch.utils.data import Dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:36.536934Z","iopub.execute_input":"2024-06-27T15:36:36.537183Z","iopub.status.idle":"2024-06-27T15:36:53.207949Z","shell.execute_reply.started":"2024-06-27T15:36:36.537161Z","shell.execute_reply":"2024-06-27T15:36:53.207129Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-06-27 15:36:42.513170: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-27 15:36:42.513264: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-27 15:36:42.608440: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.209430Z","iopub.execute_input":"2024-06-27T15:36:53.209987Z","iopub.status.idle":"2024-06-27T15:36:53.265768Z","shell.execute_reply.started":"2024-06-27T15:36:53.209960Z","shell.execute_reply":"2024-06-27T15:36:53.264804Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"PATH = '/kaggle/input/tiki-dataset-2024/tiki_data.csv'\ndf_org= pd.read_csv(PATH)\ndf_org","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.266941Z","iopub.execute_input":"2024-06-27T15:36:53.267236Z","iopub.status.idle":"2024-06-27T15:36:53.680934Z","shell.execute_reply.started":"2024-06-27T15:36:53.267212Z","shell.execute_reply":"2024-06-27T15:36:53.679879Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                             Label  \\\n0      bao đựng ốp lưng điện thoại   \n1      bao đựng ốp lưng điện thoại   \n2      bao đựng ốp lưng điện thoại   \n3      bao đựng ốp lưng điện thoại   \n4      bao đựng ốp lưng điện thoại   \n...                            ...   \n96120                bàn cafe café   \n96121                bàn cafe café   \n96122                bàn cafe café   \n96123                bàn cafe café   \n96124                bàn cafe café   \n\n                                               Name  \n0           ốp lưng xiaomi redmi case tản nhiệt đen  \n1             ốp vân da cao cấp dành samsung galaxy  \n2      ốp lưng outfitter vintage iphone màu kem msp  \n3                          ốp lưng tráng gương sony  \n4                    ốp dẻo vu da iphone plus north  \n...                                             ...  \n96120                       bàn cafe việt nhất vndt  \n96121                bàn cafe mặt vuông gỗ bạch đàn  \n96122                                    bộ bàn ghế  \n96123                                    bàn cà phê  \n96124                       bàn cafe việt nhất vndt  \n\n[96125 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bao đựng ốp lưng điện thoại</td>\n      <td>ốp lưng xiaomi redmi case tản nhiệt đen</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bao đựng ốp lưng điện thoại</td>\n      <td>ốp vân da cao cấp dành samsung galaxy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bao đựng ốp lưng điện thoại</td>\n      <td>ốp lưng outfitter vintage iphone màu kem msp</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bao đựng ốp lưng điện thoại</td>\n      <td>ốp lưng tráng gương sony</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bao đựng ốp lưng điện thoại</td>\n      <td>ốp dẻo vu da iphone plus north</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>96120</th>\n      <td>bàn cafe café</td>\n      <td>bàn cafe việt nhất vndt</td>\n    </tr>\n    <tr>\n      <th>96121</th>\n      <td>bàn cafe café</td>\n      <td>bàn cafe mặt vuông gỗ bạch đàn</td>\n    </tr>\n    <tr>\n      <th>96122</th>\n      <td>bàn cafe café</td>\n      <td>bộ bàn ghế</td>\n    </tr>\n    <tr>\n      <th>96123</th>\n      <td>bàn cafe café</td>\n      <td>bàn cà phê</td>\n    </tr>\n    <tr>\n      <th>96124</th>\n      <td>bàn cafe café</td>\n      <td>bàn cafe việt nhất vndt</td>\n    </tr>\n  </tbody>\n</table>\n<p>96125 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"labels = df_org['Label'].unique().tolist()\nlabels = [s.strip() for s in labels ]\nlabels[:5]","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.682910Z","iopub.execute_input":"2024-06-27T15:36:53.683191Z","iopub.status.idle":"2024-06-27T15:36:53.701863Z","shell.execute_reply.started":"2024-06-27T15:36:53.683167Z","shell.execute_reply":"2024-06-27T15:36:53.701035Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['bao đựng ốp lưng điện thoại',\n 'bàn ghế phòng khách',\n 'giày da nam',\n 'ghế văn phòng',\n 'bộ bàn ghế cafe']"},"metadata":{}}]},{"cell_type":"code","source":"len(labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.702828Z","iopub.execute_input":"2024-06-27T15:36:53.703073Z","iopub.status.idle":"2024-06-27T15:36:53.710256Z","shell.execute_reply.started":"2024-06-27T15:36:53.703052Z","shell.execute_reply":"2024-06-27T15:36:53.709371Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"1930"},"metadata":{}}]},{"cell_type":"code","source":"NUM_LABELS= len(labels)\n\nid2label={id:label for id,label in enumerate(labels)}\n\nlabel2id={label:id for id,label in enumerate(labels)}","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.711426Z","iopub.execute_input":"2024-06-27T15:36:53.711948Z","iopub.status.idle":"2024-06-27T15:36:53.717773Z","shell.execute_reply.started":"2024-06-27T15:36:53.711923Z","shell.execute_reply":"2024-06-27T15:36:53.716942Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#label2id\n#id2label","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.718973Z","iopub.execute_input":"2024-06-27T15:36:53.719222Z","iopub.status.idle":"2024-06-27T15:36:53.725088Z","shell.execute_reply.started":"2024-06-27T15:36:53.719200Z","shell.execute_reply":"2024-06-27T15:36:53.724353Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df_org[\"labels\"]=df_org.Label.map(lambda x: label2id[x.strip()])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.726180Z","iopub.execute_input":"2024-06-27T15:36:53.726519Z","iopub.status.idle":"2024-06-27T15:36:53.801229Z","shell.execute_reply.started":"2024-06-27T15:36:53.726496Z","shell.execute_reply":"2024-06-27T15:36:53.800090Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df_org.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.803164Z","iopub.execute_input":"2024-06-27T15:36:53.804114Z","iopub.status.idle":"2024-06-27T15:36:53.813712Z","shell.execute_reply.started":"2024-06-27T15:36:53.804082Z","shell.execute_reply":"2024-06-27T15:36:53.812700Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                         Label                                          Name  \\\n0  bao đựng ốp lưng điện thoại       ốp lưng xiaomi redmi case tản nhiệt đen   \n1  bao đựng ốp lưng điện thoại         ốp vân da cao cấp dành samsung galaxy   \n2  bao đựng ốp lưng điện thoại  ốp lưng outfitter vintage iphone màu kem msp   \n3  bao đựng ốp lưng điện thoại                      ốp lưng tráng gương sony   \n4  bao đựng ốp lưng điện thoại                ốp dẻo vu da iphone plus north   \n\n   labels  \n0       0  \n1       0  \n2       0  \n3       0  \n4       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Name</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bao đựng ốp lưng điện thoại</td>\n      <td>ốp lưng xiaomi redmi case tản nhiệt đen</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bao đựng ốp lưng điện thoại</td>\n      <td>ốp vân da cao cấp dành samsung galaxy</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bao đựng ốp lưng điện thoại</td>\n      <td>ốp lưng outfitter vintage iphone màu kem msp</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bao đựng ốp lưng điện thoại</td>\n      <td>ốp lưng tráng gương sony</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bao đựng ốp lưng điện thoại</td>\n      <td>ốp dẻo vu da iphone plus north</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.utils import shuffle\n# Kích thước của DataFrame ban đầu\nSIZE = df_org.shape[0]\n\n# Tính toán số lượng mẫu cho từng tập\ntrain_size = int(0.7 * SIZE)\nval_size = int(0.15 * SIZE)\ntest_size = SIZE - train_size - val_size  # Đảm bảo tổng là SIZE\n\n# Tạo một danh sách các chỉ số từ 0 đến (SIZE - 1) và shuffle nó\nindices = list(range(SIZE))\nindices_shuffled = shuffle(indices, random_state=42)  # random_state để cố định kết quả ngẫu nhiên\n\n# Chia các chỉ số đã xáo trộn vào các tập train, validation và test\ntrain_indices = indices_shuffled[:train_size]\nval_indices = indices_shuffled[train_size:train_size + val_size]\ntest_indices = indices_shuffled[train_size + val_size:]\n\n# Lấy dữ liệu dựa trên các chỉ số đã xáo trộn\ntrain_texts = list(df_org.loc[train_indices, 'Name'])\nval_texts = list(df_org.loc[val_indices, 'Name'])\ntest_texts = list(df_org.loc[test_indices, 'Name'])\n\ntrain_labels = list(df_org.loc[train_indices, 'labels'])\nval_labels = list(df_org.loc[val_indices, 'labels'])\ntest_labels = list(df_org.loc[test_indices, 'labels'])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.818312Z","iopub.execute_input":"2024-06-27T15:36:53.818819Z","iopub.status.idle":"2024-06-27T15:36:53.921322Z","shell.execute_reply.started":"2024-06-27T15:36:53.818793Z","shell.execute_reply":"2024-06-27T15:36:53.920523Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_labels[:10]","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.922625Z","iopub.execute_input":"2024-06-27T15:36:53.923006Z","iopub.status.idle":"2024-06-27T15:36:53.929966Z","shell.execute_reply.started":"2024-06-27T15:36:53.922970Z","shell.execute_reply":"2024-06-27T15:36:53.929094Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[50, 1028, 1079, 268, 1513, 1432, 785, 1380, 1467, 1865]"},"metadata":{}}]},{"cell_type":"code","source":"len(train_texts), len(val_texts), len(test_texts)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.931219Z","iopub.execute_input":"2024-06-27T15:36:53.931602Z","iopub.status.idle":"2024-06-27T15:36:53.939081Z","shell.execute_reply.started":"2024-06-27T15:36:53.931575Z","shell.execute_reply":"2024-06-27T15:36:53.938283Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(67287, 14418, 14420)"},"metadata":{}}]},{"cell_type":"code","source":"# Tải mô hình và tokenizer\nmodel = RobertaForSequenceClassification.from_pretrained(\"wonrax/phobert-base-vietnamese-sentiment\", num_labels=NUM_LABELS, id2label=id2label, label2id=label2id, ignore_mismatched_sizes=True)\ntokenizer = AutoTokenizer.from_pretrained(\"wonrax/phobert-base-vietnamese-sentiment\", use_fast=False)\n# Chuyển model sang thiết bị (CPU/GPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.940360Z","iopub.execute_input":"2024-06-27T15:36:53.940743Z","iopub.status.idle":"2024-06-27T15:37:00.619589Z","shell.execute_reply.started":"2024-06-27T15:36:53.940715Z","shell.execute_reply":"2024-06-27T15:37:00.618697Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/999 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a41d94df3d5c455e9165108a3af24dd4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"521a2d818c0545ad9af499d09a72a11e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at wonrax/phobert-base-vietnamese-sentiment and are newly initialized because the shapes did not match:\n- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([1930, 768]) in the model instantiated\n- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([1930]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a046c624b7e40b4a867decefcd718e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"195dd58085264a7eb38c0a2cd93c1588"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dde021bf8aa4a0d914574c0cdc98a94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/17.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b061489c18684b4b9d6ea146eab5acb2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca76c495458a47e3ab5a53e6fb06f460"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n      (position_embeddings): Embedding(258, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=1930, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Tokenizer\ntrain_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=10)\nval_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=10)\ntest_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=10)\n\n# Length check\nprint(len(train_texts), len(val_texts), len(test_texts))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:00.620779Z","iopub.execute_input":"2024-06-27T15:37:00.621063Z","iopub.status.idle":"2024-06-27T15:37:12.343218Z","shell.execute_reply.started":"2024-06-27T15:37:00.621038Z","shell.execute_reply":"2024-06-27T15:37:12.342312Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"67287 14418 14420\n","output_type":"stream"}]},{"cell_type":"code","source":"class DataLoader(Dataset):\n    \"\"\"\n    Custom Dataset class for handling tokenized text data and corresponding labels.\n    Inherits from torch.utils.data.Dataset.\n    \"\"\"\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        # Retrieve tokenized data for the given index\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        # Add the label for the given index to the item dictionary\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.344439Z","iopub.execute_input":"2024-06-27T15:37:12.344737Z","iopub.status.idle":"2024-06-27T15:37:12.351603Z","shell.execute_reply.started":"2024-06-27T15:37:12.344710Z","shell.execute_reply":"2024-06-27T15:37:12.350692Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(train_encodings.keys())","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.352801Z","iopub.execute_input":"2024-06-27T15:37:12.353146Z","iopub.status.idle":"2024-06-27T15:37:12.359985Z","shell.execute_reply.started":"2024-06-27T15:37:12.353121Z","shell.execute_reply":"2024-06-27T15:37:12.359077Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n","output_type":"stream"}]},{"cell_type":"code","source":"len(train_encodings['input_ids'][0]), len(train_encodings['token_type_ids'][0]), len(train_encodings['attention_mask'][0])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.361123Z","iopub.execute_input":"2024-06-27T15:37:12.361434Z","iopub.status.idle":"2024-06-27T15:37:12.368370Z","shell.execute_reply.started":"2024-06-27T15:37:12.361399Z","shell.execute_reply":"2024-06-27T15:37:12.367474Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(10, 10, 10)"},"metadata":{}}]},{"cell_type":"code","source":"print(train_encodings['input_ids'][0])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.369425Z","iopub.execute_input":"2024-06-27T15:37:12.369656Z","iopub.status.idle":"2024-06-27T15:37:12.377455Z","shell.execute_reply.started":"2024-06-27T15:37:12.369636Z","shell.execute_reply":"2024-06-27T15:37:12.376631Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"[0, 797, 6829, 5659, 542, 797, 6829, 5659, 5438, 2]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_labels[0])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.378617Z","iopub.execute_input":"2024-06-27T15:37:12.378988Z","iopub.status.idle":"2024-06-27T15:37:12.385266Z","shell.execute_reply.started":"2024-06-27T15:37:12.378953Z","shell.execute_reply":"2024-06-27T15:37:12.384477Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"50\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_encodings, train_labels)\n\nval_dataloader = DataLoader(val_encodings, val_labels)\n\ntest_dataset = DataLoader(test_encodings, test_labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.386349Z","iopub.execute_input":"2024-06-27T15:37:12.386662Z","iopub.status.idle":"2024-06-27T15:37:12.393253Z","shell.execute_reply.started":"2024-06-27T15:37:12.386640Z","shell.execute_reply":"2024-06-27T15:37:12.392347Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_dataloader[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.394283Z","iopub.execute_input":"2024-06-27T15:37:12.394645Z","iopub.status.idle":"2024-06-27T15:37:12.404753Z","shell.execute_reply.started":"2024-06-27T15:37:12.394616Z","shell.execute_reply":"2024-06-27T15:37:12.403846Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([   0,  797, 6829, 5659,  542,  797, 6829, 5659, 5438,    2]),\n 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n 'labels': tensor(50)}"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\ndef compute_metrics(pred):\n    # Extract true labels from the input object\n    labels = pred.label_ids\n    \n    # Obtain predicted class labels by finding the column index with the maximum probability\n    preds = pred.predictions.argmax(-1)\n    \n    # Compute macro precision, recall, and F1 score using sklearn's precision_recall_fscore_support function\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n    \n    # Calculate the accuracy score using sklearn's accuracy_score function\n    acc = accuracy_score(labels, preds)\n    \n    # Return the computed metrics as a dictionary\n    return {\n        'Accuracy': acc,\n        'F1': f1,\n        'Precision': precision,\n        'Recall': recall\n    }","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.405780Z","iopub.execute_input":"2024-06-27T15:37:12.406040Z","iopub.status.idle":"2024-06-27T15:37:12.816972Z","shell.execute_reply.started":"2024-06-27T15:37:12.406019Z","shell.execute_reply":"2024-06-27T15:37:12.816200Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import warnings\nfrom sklearn.exceptions import UndefinedMetricWarning\n\nwarnings.filterwarnings(\"ignore\", message=\"Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\")\nwarnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.817994Z","iopub.execute_input":"2024-06-27T15:37:12.818607Z","iopub.status.idle":"2024-06-27T15:37:12.823935Z","shell.execute_reply.started":"2024-06-27T15:37:12.818579Z","shell.execute_reply":"2024-06-27T15:37:12.822958Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    # The output directory where the model predictions and checkpoints will be written\n    output_dir='./pho-bert-classification', \n    do_train=True,\n    do_eval=True,\n    # The number of epochs, defaults to 3.0 \n    num_train_epochs= 15,              \n    per_device_train_batch_size=32,  \n    per_device_eval_batch_size=32,\n    # Number of steps used for a linear warmup\n    warmup_steps=500,                \n    weight_decay=0.01,\n    logging_strategy='steps',\n    # TensorBoard log directory                 \n    logging_dir='./multi-class-logs',            \n    logging_steps=300,  \n    evaluation_strategy=\"steps\",\n    eval_steps=300,\n    save_strategy=\"steps\", \n    save_steps=300,  \n    save_total_limit=2,  \n    fp16=True,\n    load_best_model_at_end=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.825075Z","iopub.execute_input":"2024-06-27T15:37:12.825360Z","iopub.status.idle":"2024-06-27T15:37:12.863826Z","shell.execute_reply.started":"2024-06-27T15:37:12.825329Z","shell.execute_reply":"2024-06-27T15:37:12.862938Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Trainer(\n    # the pre-trained model that will be fine-tuned \n    model=model,\n     # training arguments that we defined above                        \n    args=training_args,                 \n    train_dataset=train_dataloader,         \n    eval_dataset=val_dataloader,            \n    compute_metrics= compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.865132Z","iopub.execute_input":"2024-06-27T15:37:12.865603Z","iopub.status.idle":"2024-06-27T15:37:13.484808Z","shell.execute_reply.started":"2024-06-27T15:37:12.865570Z","shell.execute_reply":"2024-06-27T15:37:13.484059Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:13.485816Z","iopub.execute_input":"2024-06-27T15:37:13.486061Z","iopub.status.idle":"2024-06-27T17:00:20.395353Z","shell.execute_reply.started":"2024-06-27T15:37:13.486039Z","shell.execute_reply":"2024-06-27T17:00:20.394521Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240627_153941-sdrf57js</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/vuzle/huggingface/runs/sdrf57js' target=\"_blank\">./pho-bert-classification</a></strong> to <a href='https://wandb.ai/vuzle/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/vuzle/huggingface' target=\"_blank\">https://wandb.ai/vuzle/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/vuzle/huggingface/runs/sdrf57js' target=\"_blank\">https://wandb.ai/vuzle/huggingface/runs/sdrf57js</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='15780' max='15780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [15780/15780 1:20:17, Epoch 15/15]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>300</td>\n      <td>7.563000</td>\n      <td>7.498380</td>\n      <td>0.004023</td>\n      <td>0.000823</td>\n      <td>0.000826</td>\n      <td>0.003966</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>7.324400</td>\n      <td>7.008364</td>\n      <td>0.051880</td>\n      <td>0.025118</td>\n      <td>0.028779</td>\n      <td>0.054877</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>6.753300</td>\n      <td>6.357321</td>\n      <td>0.084478</td>\n      <td>0.044746</td>\n      <td>0.049938</td>\n      <td>0.092915</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>6.091800</td>\n      <td>5.735357</td>\n      <td>0.121445</td>\n      <td>0.071234</td>\n      <td>0.078728</td>\n      <td>0.131632</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>5.514100</td>\n      <td>5.213038</td>\n      <td>0.159662</td>\n      <td>0.098046</td>\n      <td>0.101788</td>\n      <td>0.176692</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>5.036900</td>\n      <td>4.760133</td>\n      <td>0.195034</td>\n      <td>0.132093</td>\n      <td>0.138870</td>\n      <td>0.212535</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>4.646000</td>\n      <td>4.382796</td>\n      <td>0.222638</td>\n      <td>0.154842</td>\n      <td>0.163100</td>\n      <td>0.240064</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>4.162000</td>\n      <td>4.041720</td>\n      <td>0.244763</td>\n      <td>0.177935</td>\n      <td>0.187197</td>\n      <td>0.262611</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>3.887400</td>\n      <td>3.762632</td>\n      <td>0.281246</td>\n      <td>0.207547</td>\n      <td>0.213611</td>\n      <td>0.298023</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>3.658600</td>\n      <td>3.524655</td>\n      <td>0.301567</td>\n      <td>0.232616</td>\n      <td>0.240437</td>\n      <td>0.319848</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>3.364500</td>\n      <td>3.320536</td>\n      <td>0.317312</td>\n      <td>0.248418</td>\n      <td>0.260661</td>\n      <td>0.336622</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>3.128600</td>\n      <td>3.137150</td>\n      <td>0.336801</td>\n      <td>0.269547</td>\n      <td>0.286265</td>\n      <td>0.355727</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>2.987800</td>\n      <td>2.994285</td>\n      <td>0.353308</td>\n      <td>0.291759</td>\n      <td>0.311862</td>\n      <td>0.373119</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>2.873000</td>\n      <td>2.869108</td>\n      <td>0.366001</td>\n      <td>0.305648</td>\n      <td>0.323969</td>\n      <td>0.383142</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>2.634500</td>\n      <td>2.772468</td>\n      <td>0.374948</td>\n      <td>0.314554</td>\n      <td>0.337588</td>\n      <td>0.389578</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>2.563400</td>\n      <td>2.678829</td>\n      <td>0.390484</td>\n      <td>0.336829</td>\n      <td>0.358111</td>\n      <td>0.407037</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>2.459600</td>\n      <td>2.604360</td>\n      <td>0.392079</td>\n      <td>0.343358</td>\n      <td>0.372806</td>\n      <td>0.411334</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>2.333500</td>\n      <td>2.542617</td>\n      <td>0.406090</td>\n      <td>0.350971</td>\n      <td>0.372951</td>\n      <td>0.419016</td>\n    </tr>\n    <tr>\n      <td>5700</td>\n      <td>2.230400</td>\n      <td>2.483568</td>\n      <td>0.409072</td>\n      <td>0.357813</td>\n      <td>0.379524</td>\n      <td>0.425023</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>2.189900</td>\n      <td>2.429228</td>\n      <td>0.420239</td>\n      <td>0.373004</td>\n      <td>0.401263</td>\n      <td>0.432972</td>\n    </tr>\n    <tr>\n      <td>6300</td>\n      <td>2.144000</td>\n      <td>2.391753</td>\n      <td>0.421002</td>\n      <td>0.376019</td>\n      <td>0.410428</td>\n      <td>0.433862</td>\n    </tr>\n    <tr>\n      <td>6600</td>\n      <td>1.997400</td>\n      <td>2.352993</td>\n      <td>0.429533</td>\n      <td>0.382098</td>\n      <td>0.406597</td>\n      <td>0.441039</td>\n    </tr>\n    <tr>\n      <td>6900</td>\n      <td>1.985100</td>\n      <td>2.325475</td>\n      <td>0.427036</td>\n      <td>0.383855</td>\n      <td>0.409625</td>\n      <td>0.439429</td>\n    </tr>\n    <tr>\n      <td>7200</td>\n      <td>1.963100</td>\n      <td>2.291819</td>\n      <td>0.429533</td>\n      <td>0.390843</td>\n      <td>0.419267</td>\n      <td>0.441707</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>1.846600</td>\n      <td>2.274659</td>\n      <td>0.433902</td>\n      <td>0.393202</td>\n      <td>0.423155</td>\n      <td>0.444877</td>\n    </tr>\n    <tr>\n      <td>7800</td>\n      <td>1.808600</td>\n      <td>2.257437</td>\n      <td>0.439451</td>\n      <td>0.398421</td>\n      <td>0.426991</td>\n      <td>0.450494</td>\n    </tr>\n    <tr>\n      <td>8100</td>\n      <td>1.792800</td>\n      <td>2.238758</td>\n      <td>0.437786</td>\n      <td>0.401835</td>\n      <td>0.436820</td>\n      <td>0.451238</td>\n    </tr>\n    <tr>\n      <td>8400</td>\n      <td>1.787300</td>\n      <td>2.208481</td>\n      <td>0.443959</td>\n      <td>0.406124</td>\n      <td>0.435314</td>\n      <td>0.454343</td>\n    </tr>\n    <tr>\n      <td>8700</td>\n      <td>1.654900</td>\n      <td>2.210768</td>\n      <td>0.441046</td>\n      <td>0.402658</td>\n      <td>0.429144</td>\n      <td>0.450054</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>1.662700</td>\n      <td>2.187226</td>\n      <td>0.447427</td>\n      <td>0.411797</td>\n      <td>0.437086</td>\n      <td>0.459199</td>\n    </tr>\n    <tr>\n      <td>9300</td>\n      <td>1.665500</td>\n      <td>2.177855</td>\n      <td>0.445693</td>\n      <td>0.412897</td>\n      <td>0.441826</td>\n      <td>0.457144</td>\n    </tr>\n    <tr>\n      <td>9600</td>\n      <td>1.625800</td>\n      <td>2.169132</td>\n      <td>0.450479</td>\n      <td>0.416233</td>\n      <td>0.446971</td>\n      <td>0.460833</td>\n    </tr>\n    <tr>\n      <td>9900</td>\n      <td>1.550500</td>\n      <td>2.169214</td>\n      <td>0.443265</td>\n      <td>0.412400</td>\n      <td>0.440022</td>\n      <td>0.456231</td>\n    </tr>\n    <tr>\n      <td>10200</td>\n      <td>1.552200</td>\n      <td>2.155730</td>\n      <td>0.447496</td>\n      <td>0.415680</td>\n      <td>0.443929</td>\n      <td>0.458226</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>1.564000</td>\n      <td>2.136694</td>\n      <td>0.455126</td>\n      <td>0.423927</td>\n      <td>0.454827</td>\n      <td>0.464808</td>\n    </tr>\n    <tr>\n      <td>10800</td>\n      <td>1.461700</td>\n      <td>2.142002</td>\n      <td>0.448537</td>\n      <td>0.419223</td>\n      <td>0.449946</td>\n      <td>0.457859</td>\n    </tr>\n    <tr>\n      <td>11100</td>\n      <td>1.476900</td>\n      <td>2.136418</td>\n      <td>0.453600</td>\n      <td>0.424181</td>\n      <td>0.452072</td>\n      <td>0.462432</td>\n    </tr>\n    <tr>\n      <td>11400</td>\n      <td>1.478400</td>\n      <td>2.131004</td>\n      <td>0.450964</td>\n      <td>0.423735</td>\n      <td>0.448171</td>\n      <td>0.463844</td>\n    </tr>\n    <tr>\n      <td>11700</td>\n      <td>1.432700</td>\n      <td>2.129603</td>\n      <td>0.453600</td>\n      <td>0.425327</td>\n      <td>0.451008</td>\n      <td>0.463718</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>1.388600</td>\n      <td>2.129586</td>\n      <td>0.452143</td>\n      <td>0.423842</td>\n      <td>0.449673</td>\n      <td>0.462870</td>\n    </tr>\n    <tr>\n      <td>12300</td>\n      <td>1.407800</td>\n      <td>2.122313</td>\n      <td>0.453322</td>\n      <td>0.426751</td>\n      <td>0.456837</td>\n      <td>0.464570</td>\n    </tr>\n    <tr>\n      <td>12600</td>\n      <td>1.404500</td>\n      <td>2.119130</td>\n      <td>0.453600</td>\n      <td>0.428069</td>\n      <td>0.457053</td>\n      <td>0.463533</td>\n    </tr>\n    <tr>\n      <td>12900</td>\n      <td>1.334000</td>\n      <td>2.122989</td>\n      <td>0.454987</td>\n      <td>0.429009</td>\n      <td>0.460146</td>\n      <td>0.464214</td>\n    </tr>\n    <tr>\n      <td>13200</td>\n      <td>1.346900</td>\n      <td>2.117332</td>\n      <td>0.453530</td>\n      <td>0.426591</td>\n      <td>0.454139</td>\n      <td>0.462198</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>1.351000</td>\n      <td>2.112800</td>\n      <td>0.454016</td>\n      <td>0.429475</td>\n      <td>0.455184</td>\n      <td>0.464445</td>\n    </tr>\n    <tr>\n      <td>13800</td>\n      <td>1.322200</td>\n      <td>2.117969</td>\n      <td>0.452906</td>\n      <td>0.427876</td>\n      <td>0.452246</td>\n      <td>0.463099</td>\n    </tr>\n    <tr>\n      <td>14100</td>\n      <td>1.290800</td>\n      <td>2.113054</td>\n      <td>0.453114</td>\n      <td>0.429007</td>\n      <td>0.454306</td>\n      <td>0.463918</td>\n    </tr>\n    <tr>\n      <td>14400</td>\n      <td>1.296900</td>\n      <td>2.111303</td>\n      <td>0.453738</td>\n      <td>0.430125</td>\n      <td>0.455640</td>\n      <td>0.464679</td>\n    </tr>\n    <tr>\n      <td>14700</td>\n      <td>1.312100</td>\n      <td>2.109722</td>\n      <td>0.454432</td>\n      <td>0.430934</td>\n      <td>0.454473</td>\n      <td>0.465067</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>1.260600</td>\n      <td>2.110191</td>\n      <td>0.454155</td>\n      <td>0.431102</td>\n      <td>0.454277</td>\n      <td>0.464266</td>\n    </tr>\n    <tr>\n      <td>15300</td>\n      <td>1.255100</td>\n      <td>2.110785</td>\n      <td>0.452975</td>\n      <td>0.430138</td>\n      <td>0.452937</td>\n      <td>0.463299</td>\n    </tr>\n    <tr>\n      <td>15600</td>\n      <td>1.273600</td>\n      <td>2.110539</td>\n      <td>0.454848</td>\n      <td>0.432095</td>\n      <td>0.455322</td>\n      <td>0.465043</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=15780, training_loss=2.5069257777302285, metrics={'train_runtime': 4986.4916, 'train_samples_per_second': 202.408, 'train_steps_per_second': 3.165, 'total_flos': 5276490824424600.0, 'train_loss': 2.5069257777302285, 'epoch': 15.0})"},"metadata":{}}]},{"cell_type":"code","source":"q=[trainer.evaluate(eval_dataset=df_org) for df_org in [train_dataloader, val_dataloader, test_dataset]]\n\npd.DataFrame(q, index=[\"train\",\"val\",\"test\"]).iloc[:,:5]","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:00:20.396454Z","iopub.execute_input":"2024-06-27T17:00:20.396812Z","iopub.status.idle":"2024-06-27T17:02:14.834493Z","shell.execute_reply.started":"2024-06-27T17:00:20.396779Z","shell.execute_reply":"2024-06-27T17:02:14.833359Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1504' max='1052' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1052/1052 01:54]\n    </div>\n    "},"metadata":{}},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"       eval_loss  eval_Accuracy   eval_F1  eval_Precision  eval_Recall\ntrain   1.125566       0.666473  0.653848        0.701755     0.663133\nval     2.109722       0.454432  0.430934        0.454473     0.465067\ntest    2.080833       0.462691  0.432079        0.460369     0.464698","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eval_loss</th>\n      <th>eval_Accuracy</th>\n      <th>eval_F1</th>\n      <th>eval_Precision</th>\n      <th>eval_Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>train</th>\n      <td>1.125566</td>\n      <td>0.666473</td>\n      <td>0.653848</td>\n      <td>0.701755</td>\n      <td>0.663133</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>2.109722</td>\n      <td>0.454432</td>\n      <td>0.430934</td>\n      <td>0.454473</td>\n      <td>0.465067</td>\n    </tr>\n    <tr>\n      <th>test</th>\n      <td>2.080833</td>\n      <td>0.462691</td>\n      <td>0.432079</td>\n      <td>0.460369</td>\n      <td>0.464698</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def predict(text):\n    \"\"\"\n    Predicts the class label for a given input text\n\n    Args:\n        text (str): The input text for which the class label needs to be predicted.\n\n    Returns:\n        probs (torch.Tensor): Class probabilities for the input text.\n        pred_label_idx (torch.Tensor): The index of the predicted class label.\n        pred_label (str): The predicted class label.\n    \"\"\"\n    # Tokenize the input text and move tensors to the GPU if available\n    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(\"cuda\")\n\n    # Get model output (logits)\n    outputs = model(**inputs)\n\n    probs = outputs[0].softmax(1)\n    \"\"\" Explanation outputs: The BERT model returns a tuple containing the output logits (and possibly other elements depending on the model configuration). In this case, the output logits are the first element in the tuple, which is why we access it using outputs[0].\n\n    outputs[0]: This is a tensor containing the raw output logits for each class. The shape of the tensor is (batch_size, num_classes) where batch_size is the number of input samples (in this case, 1, as we are predicting for a single input text) and num_classes is the number of target classes.\n\n    softmax(1): The softmax function is applied along dimension 1 (the class dimension) to convert the raw logits into class probabilities. Softmax normalizes the logits so that they sum to 1, making them interpretable as probabilities. \"\"\"\n    \n    pred_label_idx = probs.argmax()\n    \n    pred_label = model.config.id2label[pred_label_idx.item()]\n\n    return probs, pred_label_idx, pred_label","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:02:14.841820Z","iopub.execute_input":"2024-06-27T17:02:14.842471Z","iopub.status.idle":"2024-06-27T17:02:14.852929Z","shell.execute_reply.started":"2024-06-27T17:02:14.842428Z","shell.execute_reply":"2024-06-27T17:02:14.851681Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Test with a an example text in Turkish\ntext = \"ghế hq\"\n# \"Machine Learning itself is moving towards more and more automated\"\npredict(text)[2]","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:02:14.854077Z","iopub.execute_input":"2024-06-27T17:02:14.854449Z","iopub.status.idle":"2024-06-27T17:02:14.913050Z","shell.execute_reply.started":"2024-06-27T17:02:14.854421Z","shell.execute_reply":"2024-06-27T17:02:14.912088Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"'ghế văn phòng'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Save model for inference","metadata":{}},{"cell_type":"code","source":"model_path = \"pho-bert-classification\"\ntrainer.save_model(model_path)\ntokenizer.save_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:02:14.914324Z","iopub.execute_input":"2024-06-27T17:02:14.914866Z","iopub.status.idle":"2024-06-27T17:02:16.036227Z","shell.execute_reply.started":"2024-06-27T17:02:14.914833Z","shell.execute_reply":"2024-06-27T17:02:16.035159Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"('pho-bert-classification/tokenizer_config.json',\n 'pho-bert-classification/special_tokens_map.json',\n 'pho-bert-classification/vocab.txt',\n 'pho-bert-classification/bpe.codes',\n 'pho-bert-classification/added_tokens.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Re-Load saved model for inference","metadata":{}},{"cell_type":"code","source":"model_path = \"pho-bert-classification\"","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:02:16.037567Z","iopub.execute_input":"2024-06-27T17:02:16.037931Z","iopub.status.idle":"2024-06-27T17:02:16.043081Z","shell.execute_reply.started":"2024-06-27T17:02:16.037896Z","shell.execute_reply":"2024-06-27T17:02:16.041999Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Load model and tokenizer\nmodel = RobertaForSequenceClassification.from_pretrained(model_path)\ntokenizer= AutoTokenizer.from_pretrained(model_path)\n# Switch model to device (CPU/GPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:02:16.044462Z","iopub.execute_input":"2024-06-27T17:02:16.044899Z","iopub.status.idle":"2024-06-27T17:02:16.580152Z","shell.execute_reply.started":"2024-06-27T17:02:16.044863Z","shell.execute_reply":"2024-06-27T17:02:16.579131Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n      (position_embeddings): Embedding(258, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=1930, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"#%%time\n# Apply predict function to each row in the Name column\n#df_org['pred_label'] = df_org['Name'].apply(lambda x: predict(x)[2])","metadata":{"execution":{"iopub.status.busy":"2024-06-26T10:58:31.565322Z","iopub.execute_input":"2024-06-26T10:58:31.565938Z","iopub.status.idle":"2024-06-26T11:17:53.644302Z","shell.execute_reply.started":"2024-06-26T10:58:31.565903Z","shell.execute_reply":"2024-06-26T11:17:53.643045Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"#df_org","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:21:54.101345Z","iopub.execute_input":"2024-06-26T11:21:54.101749Z","iopub.status.idle":"2024-06-26T11:21:54.122873Z","shell.execute_reply.started":"2024-06-26T11:21:54.101714Z","shell.execute_reply":"2024-06-26T11:21:54.121882Z"},"trusted":true},"execution_count":117,"outputs":[{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"                             Label  \\\n0      bao đựng ốp lưng điện thoại   \n1      bao đựng ốp lưng điện thoại   \n2      bao đựng ốp lưng điện thoại   \n3      bao đựng ốp lưng điện thoại   \n4      bao đựng ốp lưng điện thoại   \n...                            ...   \n96072                  lắc tay nam   \n96073                  lắc tay nam   \n96074                  lắc tay nam   \n96075                  lắc tay nam   \n96076                  lắc tay nam   \n\n                                                    Name  labels  \\\n0                              ốp lưng carbon iphone xám       0   \n1            ốp lưng lenovo vibe nhựa tpu chống trơn màu       0   \n2      ốp lưng note neo tráng gương viền kim loại màu...       0   \n3                                 bao da đựng điện thoại       0   \n4                       ốp lưng viva flex iphone màu đen       0   \n...                                                  ...     ...   \n96072                             vòng tay handmade tank    1927   \n96073             vòng tay nam màu kết hợp vàng bạc toma    1927   \n96074                          vòng tay nam màu bạc toma    1927   \n96075                            lắc nam inox thời trang    1927   \n96076                                       vòng tay nam    1927   \n\n                        pred_label  \n0      bao đựng ốp lưng điện thoại  \n1      bao đựng ốp lưng điện thoại  \n2      bao đựng ốp lưng điện thoại  \n3      bao đựng ốp lưng điện thoại  \n4      bao đựng ốp lưng điện thoại  \n...                            ...  \n96072                   lắc tay nữ  \n96073                  lắc tay nam  \n96074                  lắc tay nam  \n96075                  lắc tay nam  \n96076                  lắc tay nam  \n\n[95967 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Name</th>\n      <th>labels</th>\n      <th>pred_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bao đựng ốp lưng điện thoại</td>\n      <td>ốp lưng carbon iphone xám</td>\n      <td>0</td>\n      <td>bao đựng ốp lưng điện thoại</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bao đựng ốp lưng điện thoại</td>\n      <td>ốp lưng lenovo vibe nhựa tpu chống trơn màu</td>\n      <td>0</td>\n      <td>bao đựng ốp lưng điện thoại</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bao đựng ốp lưng điện thoại</td>\n      <td>ốp lưng note neo tráng gương viền kim loại màu...</td>\n      <td>0</td>\n      <td>bao đựng ốp lưng điện thoại</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bao đựng ốp lưng điện thoại</td>\n      <td>bao da đựng điện thoại</td>\n      <td>0</td>\n      <td>bao đựng ốp lưng điện thoại</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bao đựng ốp lưng điện thoại</td>\n      <td>ốp lưng viva flex iphone màu đen</td>\n      <td>0</td>\n      <td>bao đựng ốp lưng điện thoại</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>96072</th>\n      <td>lắc tay nam</td>\n      <td>vòng tay handmade tank</td>\n      <td>1927</td>\n      <td>lắc tay nữ</td>\n    </tr>\n    <tr>\n      <th>96073</th>\n      <td>lắc tay nam</td>\n      <td>vòng tay nam màu kết hợp vàng bạc toma</td>\n      <td>1927</td>\n      <td>lắc tay nam</td>\n    </tr>\n    <tr>\n      <th>96074</th>\n      <td>lắc tay nam</td>\n      <td>vòng tay nam màu bạc toma</td>\n      <td>1927</td>\n      <td>lắc tay nam</td>\n    </tr>\n    <tr>\n      <th>96075</th>\n      <td>lắc tay nam</td>\n      <td>lắc nam inox thời trang</td>\n      <td>1927</td>\n      <td>lắc tay nam</td>\n    </tr>\n    <tr>\n      <th>96076</th>\n      <td>lắc tay nam</td>\n      <td>vòng tay nam</td>\n      <td>1927</td>\n      <td>lắc tay nam</td>\n    </tr>\n  </tbody>\n</table>\n<p>95967 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Create DataFrame containing only the observations where Label != pred_label\n#df_mismatch = df_org[df_org['Label'] != df_org['pred_label']]","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:28:59.390574Z","iopub.execute_input":"2024-06-26T11:28:59.391024Z","iopub.status.idle":"2024-06-26T11:28:59.423923Z","shell.execute_reply.started":"2024-06-26T11:28:59.390994Z","shell.execute_reply":"2024-06-26T11:28:59.422913Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"#df_mismatch","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:29:11.773148Z","iopub.execute_input":"2024-06-26T11:29:11.773989Z","iopub.status.idle":"2024-06-26T11:29:11.790979Z","shell.execute_reply.started":"2024-06-26T11:29:11.773957Z","shell.execute_reply":"2024-06-26T11:29:11.789823Z"},"trusted":true},"execution_count":121,"outputs":[{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"                             Label  \\\n28     bao đựng ốp lưng điện thoại   \n46     bao đựng ốp lưng điện thoại   \n51             bàn ghế phòng khách   \n55             bàn ghế phòng khách   \n56             bàn ghế phòng khách   \n...                            ...   \n96049                  lắc tay nam   \n96050                  lắc tay nam   \n96066                  lắc tay nam   \n96069                  lắc tay nam   \n96072                  lắc tay nam   \n\n                                                    Name  labels  \\\n28                    ốp gương trang điểm đính đá iphone       0   \n46                         ốp dẻo doanh nhân xi bóng đầu       0   \n51                               salon hương voi tay món       1   \n55                       bàn ghế minh quốc chạm hồng trĩ       1   \n56                          trường kỉ ngũ sơn khảm ốc cũ       1   \n...                                                  ...     ...   \n96049  lắc tay mạ vàng phong cách âu mỹ kèm vòng tay ...    1927   \n96050    lắc tay nam dây xích chất liệu thép titan ko rỉ    1927   \n96066  lắc tay mạ bạc phong cách âu mỹ kèm vòng tay t...    1927   \n96069  lắc tay mạ vàng phong cách âu mỹ kèm vòng tay ...    1927   \n96072                             vòng tay handmade tank    1927   \n\n                   pred_label  \n28           gương trang điểm  \n46            găng tay bảo hộ  \n51                 sofa salon  \n55           bàn ghế sân vườn  \n56     ghế hội trường rạp hát  \n...                       ...  \n96049              lắc tay nữ  \n96050                    xích  \n96066              lắc tay nữ  \n96069              lắc tay nữ  \n96072              lắc tay nữ  \n\n[40149 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Name</th>\n      <th>labels</th>\n      <th>pred_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>28</th>\n      <td>bao đựng ốp lưng điện thoại</td>\n      <td>ốp gương trang điểm đính đá iphone</td>\n      <td>0</td>\n      <td>gương trang điểm</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>bao đựng ốp lưng điện thoại</td>\n      <td>ốp dẻo doanh nhân xi bóng đầu</td>\n      <td>0</td>\n      <td>găng tay bảo hộ</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>bàn ghế phòng khách</td>\n      <td>salon hương voi tay món</td>\n      <td>1</td>\n      <td>sofa salon</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>bàn ghế phòng khách</td>\n      <td>bàn ghế minh quốc chạm hồng trĩ</td>\n      <td>1</td>\n      <td>bàn ghế sân vườn</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>bàn ghế phòng khách</td>\n      <td>trường kỉ ngũ sơn khảm ốc cũ</td>\n      <td>1</td>\n      <td>ghế hội trường rạp hát</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>96049</th>\n      <td>lắc tay nam</td>\n      <td>lắc tay mạ vàng phong cách âu mỹ kèm vòng tay ...</td>\n      <td>1927</td>\n      <td>lắc tay nữ</td>\n    </tr>\n    <tr>\n      <th>96050</th>\n      <td>lắc tay nam</td>\n      <td>lắc tay nam dây xích chất liệu thép titan ko rỉ</td>\n      <td>1927</td>\n      <td>xích</td>\n    </tr>\n    <tr>\n      <th>96066</th>\n      <td>lắc tay nam</td>\n      <td>lắc tay mạ bạc phong cách âu mỹ kèm vòng tay t...</td>\n      <td>1927</td>\n      <td>lắc tay nữ</td>\n    </tr>\n    <tr>\n      <th>96069</th>\n      <td>lắc tay nam</td>\n      <td>lắc tay mạ vàng phong cách âu mỹ kèm vòng tay ...</td>\n      <td>1927</td>\n      <td>lắc tay nữ</td>\n    </tr>\n    <tr>\n      <th>96072</th>\n      <td>lắc tay nam</td>\n      <td>vòng tay handmade tank</td>\n      <td>1927</td>\n      <td>lắc tay nữ</td>\n    </tr>\n  </tbody>\n</table>\n<p>40149 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Save the resulting DataFrame to a CSV file\n#df_mismatch_check = df_mismatch[['Name','Label','pred_label']]","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:37:41.681822Z","iopub.execute_input":"2024-06-26T11:37:41.682195Z","iopub.status.idle":"2024-06-26T11:37:41.695809Z","shell.execute_reply.started":"2024-06-26T11:37:41.682165Z","shell.execute_reply":"2024-06-26T11:37:41.694538Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"#df_mismatch_check.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:39:30.129400Z","iopub.execute_input":"2024-06-26T11:39:30.129797Z","iopub.status.idle":"2024-06-26T11:39:30.140487Z","shell.execute_reply.started":"2024-06-26T11:39:30.129754Z","shell.execute_reply":"2024-06-26T11:39:30.139015Z"},"trusted":true},"execution_count":132,"outputs":[{"execution_count":132,"output_type":"execute_result","data":{"text/plain":"(40149, 3)"},"metadata":{}}]},{"cell_type":"code","source":"# Lưu DataFrame vào tệp CSV\n#df_mismatch_check.to_csv('df_mismatch_check.csv', encoding = 'utf-8', index=False)\n\n# Tạo liên kết tải về\n#from IPython.display import FileLink\n\n#FileLink('df_mismatch_check.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:37:59.814738Z","iopub.execute_input":"2024-06-26T11:37:59.815502Z","iopub.status.idle":"2024-06-26T11:38:00.050158Z","shell.execute_reply.started":"2024-06-26T11:37:59.815469Z","shell.execute_reply":"2024-06-26T11:38:00.048395Z"},"trusted":true},"execution_count":131,"outputs":[{"execution_count":131,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/df_mismatch_check.csv","text/html":"<a href='df_mismatch_check.csv' target='_blank'>df_mismatch_check.csv</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"import shutil\nfrom IPython.display import FileLink\n\n# Nén thư mục thành tệp ZIP\nshutil.make_archive('pho-bert-classification', 'zip', 'pho-bert-classification')\n\n# Tạo liên kết tải về\nFileLink('pho-bert-classification.zip')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:02:16.581945Z","iopub.execute_input":"2024-06-27T17:02:16.582222Z","iopub.status.idle":"2024-06-27T17:05:11.859705Z","shell.execute_reply.started":"2024-06-27T17:02:16.582196Z","shell.execute_reply":"2024-06-27T17:05:11.858383Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/pho-bert-classification.zip","text/html":"<a href='pho-bert-classification.zip' target='_blank'>pho-bert-classification.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"model = RobertaForSequenceClassification.from_pretrained(model_path)\ntokenizer= AutoTokenizer.from_pretrained(model_path)\nnlp= pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:10:42.010837Z","iopub.execute_input":"2024-06-27T17:10:42.011200Z","iopub.status.idle":"2024-06-27T17:10:42.423296Z","shell.execute_reply.started":"2024-06-27T17:10:42.011170Z","shell.execute_reply":"2024-06-27T17:10:42.422050Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"nlp(\"ốp gương trang điểm đính đá iphone\") ","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:10:43.582971Z","iopub.execute_input":"2024-06-27T17:10:43.583342Z","iopub.status.idle":"2024-06-27T17:10:43.744676Z","shell.execute_reply.started":"2024-06-27T17:10:43.583288Z","shell.execute_reply":"2024-06-27T17:10:43.743042Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"[{'label': 'gương trang điểm', 'score': 0.44541189074516296}]"},"metadata":{}}]}]}