{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8800059,"sourceType":"datasetVersion","datasetId":5291812}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch, os\nimport pandas as pd\nimport numpy as np\nfrom transformers import pipeline, BertForSequenceClassification, BertTokenizerFast\nfrom transformers import RobertaForSequenceClassification, AutoTokenizer\nfrom torch.utils.data import Dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:36.536934Z","iopub.execute_input":"2024-06-27T15:36:36.537183Z","iopub.status.idle":"2024-06-27T15:36:53.207949Z","shell.execute_reply.started":"2024-06-27T15:36:36.537161Z","shell.execute_reply":"2024-06-27T15:36:53.207129Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-06-27 15:36:42.513170: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-27 15:36:42.513264: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-27 15:36:42.608440: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.209430Z","iopub.execute_input":"2024-06-27T15:36:53.209987Z","iopub.status.idle":"2024-06-27T15:36:53.265768Z","shell.execute_reply.started":"2024-06-27T15:36:53.209960Z","shell.execute_reply":"2024-06-27T15:36:53.264804Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"PATH = '/kaggle/input/tiki-dataset-2024/tiki_data.csv'\ndf_org= pd.read_csv(PATH)\ndf_org","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.266941Z","iopub.execute_input":"2024-06-27T15:36:53.267236Z","iopub.status.idle":"2024-06-27T15:36:53.680934Z","shell.execute_reply.started":"2024-06-27T15:36:53.267212Z","shell.execute_reply":"2024-06-27T15:36:53.679879Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                             Label  \\\n0      bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i   \n1      bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i   \n2      bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i   \n3      bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i   \n4      bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i   \n...                            ...   \n96120                b√†n cafe caf√©   \n96121                b√†n cafe caf√©   \n96122                b√†n cafe caf√©   \n96123                b√†n cafe caf√©   \n96124                b√†n cafe caf√©   \n\n                                               Name  \n0           ·ªëp l∆∞ng xiaomi redmi case t·∫£n nhi·ªát ƒëen  \n1             ·ªëp v√¢n da cao c·∫•p d√†nh samsung galaxy  \n2      ·ªëp l∆∞ng outfitter vintage iphone m√†u kem msp  \n3                          ·ªëp l∆∞ng tr√°ng g∆∞∆°ng sony  \n4                    ·ªëp d·∫ªo vu da iphone plus north  \n...                                             ...  \n96120                       b√†n cafe vi·ªát nh·∫•t vndt  \n96121                b√†n cafe m·∫∑t vu√¥ng g·ªó b·∫°ch ƒë√†n  \n96122                                    b·ªô b√†n gh·∫ø  \n96123                                    b√†n c√† ph√™  \n96124                       b√†n cafe vi·ªát nh·∫•t vndt  \n\n[96125 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n      <td>·ªëp l∆∞ng xiaomi redmi case t·∫£n nhi·ªát ƒëen</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n      <td>·ªëp v√¢n da cao c·∫•p d√†nh samsung galaxy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n      <td>·ªëp l∆∞ng outfitter vintage iphone m√†u kem msp</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n      <td>·ªëp l∆∞ng tr√°ng g∆∞∆°ng sony</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n      <td>·ªëp d·∫ªo vu da iphone plus north</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>96120</th>\n      <td>b√†n cafe caf√©</td>\n      <td>b√†n cafe vi·ªát nh·∫•t vndt</td>\n    </tr>\n    <tr>\n      <th>96121</th>\n      <td>b√†n cafe caf√©</td>\n      <td>b√†n cafe m·∫∑t vu√¥ng g·ªó b·∫°ch ƒë√†n</td>\n    </tr>\n    <tr>\n      <th>96122</th>\n      <td>b√†n cafe caf√©</td>\n      <td>b·ªô b√†n gh·∫ø</td>\n    </tr>\n    <tr>\n      <th>96123</th>\n      <td>b√†n cafe caf√©</td>\n      <td>b√†n c√† ph√™</td>\n    </tr>\n    <tr>\n      <th>96124</th>\n      <td>b√†n cafe caf√©</td>\n      <td>b√†n cafe vi·ªát nh·∫•t vndt</td>\n    </tr>\n  </tbody>\n</table>\n<p>96125 rows √ó 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"labels = df_org['Label'].unique().tolist()\nlabels = [s.strip() for s in labels ]\nlabels[:5]","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.682910Z","iopub.execute_input":"2024-06-27T15:36:53.683191Z","iopub.status.idle":"2024-06-27T15:36:53.701863Z","shell.execute_reply.started":"2024-06-27T15:36:53.683167Z","shell.execute_reply":"2024-06-27T15:36:53.701035Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i',\n 'b√†n gh·∫ø ph√≤ng kh√°ch',\n 'gi√†y da nam',\n 'gh·∫ø vƒÉn ph√≤ng',\n 'b·ªô b√†n gh·∫ø cafe']"},"metadata":{}}]},{"cell_type":"code","source":"len(labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.702828Z","iopub.execute_input":"2024-06-27T15:36:53.703073Z","iopub.status.idle":"2024-06-27T15:36:53.710256Z","shell.execute_reply.started":"2024-06-27T15:36:53.703052Z","shell.execute_reply":"2024-06-27T15:36:53.709371Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"1930"},"metadata":{}}]},{"cell_type":"code","source":"NUM_LABELS= len(labels)\n\nid2label={id:label for id,label in enumerate(labels)}\n\nlabel2id={label:id for id,label in enumerate(labels)}","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.711426Z","iopub.execute_input":"2024-06-27T15:36:53.711948Z","iopub.status.idle":"2024-06-27T15:36:53.717773Z","shell.execute_reply.started":"2024-06-27T15:36:53.711923Z","shell.execute_reply":"2024-06-27T15:36:53.716942Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#label2id\n#id2label","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.718973Z","iopub.execute_input":"2024-06-27T15:36:53.719222Z","iopub.status.idle":"2024-06-27T15:36:53.725088Z","shell.execute_reply.started":"2024-06-27T15:36:53.719200Z","shell.execute_reply":"2024-06-27T15:36:53.724353Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df_org[\"labels\"]=df_org.Label.map(lambda x: label2id[x.strip()])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.726180Z","iopub.execute_input":"2024-06-27T15:36:53.726519Z","iopub.status.idle":"2024-06-27T15:36:53.801229Z","shell.execute_reply.started":"2024-06-27T15:36:53.726496Z","shell.execute_reply":"2024-06-27T15:36:53.800090Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df_org.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.803164Z","iopub.execute_input":"2024-06-27T15:36:53.804114Z","iopub.status.idle":"2024-06-27T15:36:53.813712Z","shell.execute_reply.started":"2024-06-27T15:36:53.804082Z","shell.execute_reply":"2024-06-27T15:36:53.812700Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                         Label                                          Name  \\\n0  bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i       ·ªëp l∆∞ng xiaomi redmi case t·∫£n nhi·ªát ƒëen   \n1  bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i         ·ªëp v√¢n da cao c·∫•p d√†nh samsung galaxy   \n2  bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i  ·ªëp l∆∞ng outfitter vintage iphone m√†u kem msp   \n3  bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i                      ·ªëp l∆∞ng tr√°ng g∆∞∆°ng sony   \n4  bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i                ·ªëp d·∫ªo vu da iphone plus north   \n\n   labels  \n0       0  \n1       0  \n2       0  \n3       0  \n4       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Name</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n      <td>·ªëp l∆∞ng xiaomi redmi case t·∫£n nhi·ªát ƒëen</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n      <td>·ªëp v√¢n da cao c·∫•p d√†nh samsung galaxy</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n      <td>·ªëp l∆∞ng outfitter vintage iphone m√†u kem msp</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n      <td>·ªëp l∆∞ng tr√°ng g∆∞∆°ng sony</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n      <td>·ªëp d·∫ªo vu da iphone plus north</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.utils import shuffle\n# K√≠ch th∆∞·ªõc c·ªßa DataFrame ban ƒë·∫ßu\nSIZE = df_org.shape[0]\n\n# T√≠nh to√°n s·ªë l∆∞·ª£ng m·∫´u cho t·ª´ng t·∫≠p\ntrain_size = int(0.7 * SIZE)\nval_size = int(0.15 * SIZE)\ntest_size = SIZE - train_size - val_size  # ƒê·∫£m b·∫£o t·ªïng l√† SIZE\n\n# T·∫°o m·ªôt danh s√°ch c√°c ch·ªâ s·ªë t·ª´ 0 ƒë·∫øn (SIZE - 1) v√† shuffle n√≥\nindices = list(range(SIZE))\nindices_shuffled = shuffle(indices, random_state=42)  # random_state ƒë·ªÉ c·ªë ƒë·ªãnh k·∫øt qu·∫£ ng·∫´u nhi√™n\n\n# Chia c√°c ch·ªâ s·ªë ƒë√£ x√°o tr·ªôn v√†o c√°c t·∫≠p train, validation v√† test\ntrain_indices = indices_shuffled[:train_size]\nval_indices = indices_shuffled[train_size:train_size + val_size]\ntest_indices = indices_shuffled[train_size + val_size:]\n\n# L·∫•y d·ªØ li·ªáu d·ª±a tr√™n c√°c ch·ªâ s·ªë ƒë√£ x√°o tr·ªôn\ntrain_texts = list(df_org.loc[train_indices, 'Name'])\nval_texts = list(df_org.loc[val_indices, 'Name'])\ntest_texts = list(df_org.loc[test_indices, 'Name'])\n\ntrain_labels = list(df_org.loc[train_indices, 'labels'])\nval_labels = list(df_org.loc[val_indices, 'labels'])\ntest_labels = list(df_org.loc[test_indices, 'labels'])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.818312Z","iopub.execute_input":"2024-06-27T15:36:53.818819Z","iopub.status.idle":"2024-06-27T15:36:53.921322Z","shell.execute_reply.started":"2024-06-27T15:36:53.818793Z","shell.execute_reply":"2024-06-27T15:36:53.920523Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_labels[:10]","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.922625Z","iopub.execute_input":"2024-06-27T15:36:53.923006Z","iopub.status.idle":"2024-06-27T15:36:53.929966Z","shell.execute_reply.started":"2024-06-27T15:36:53.922970Z","shell.execute_reply":"2024-06-27T15:36:53.929094Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[50, 1028, 1079, 268, 1513, 1432, 785, 1380, 1467, 1865]"},"metadata":{}}]},{"cell_type":"code","source":"len(train_texts), len(val_texts), len(test_texts)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.931219Z","iopub.execute_input":"2024-06-27T15:36:53.931602Z","iopub.status.idle":"2024-06-27T15:36:53.939081Z","shell.execute_reply.started":"2024-06-27T15:36:53.931575Z","shell.execute_reply":"2024-06-27T15:36:53.938283Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(67287, 14418, 14420)"},"metadata":{}}]},{"cell_type":"code","source":"# T·∫£i m√¥ h√¨nh v√† tokenizer\nmodel = RobertaForSequenceClassification.from_pretrained(\"wonrax/phobert-base-vietnamese-sentiment\", num_labels=NUM_LABELS, id2label=id2label, label2id=label2id, ignore_mismatched_sizes=True)\ntokenizer = AutoTokenizer.from_pretrained(\"wonrax/phobert-base-vietnamese-sentiment\", use_fast=False)\n# Chuy·ªÉn model sang thi·∫øt b·ªã (CPU/GPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:36:53.940360Z","iopub.execute_input":"2024-06-27T15:36:53.940743Z","iopub.status.idle":"2024-06-27T15:37:00.619589Z","shell.execute_reply.started":"2024-06-27T15:36:53.940715Z","shell.execute_reply":"2024-06-27T15:37:00.618697Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/999 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a41d94df3d5c455e9165108a3af24dd4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"521a2d818c0545ad9af499d09a72a11e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at wonrax/phobert-base-vietnamese-sentiment and are newly initialized because the shapes did not match:\n- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([1930, 768]) in the model instantiated\n- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([1930]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a046c624b7e40b4a867decefcd718e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"195dd58085264a7eb38c0a2cd93c1588"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dde021bf8aa4a0d914574c0cdc98a94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/17.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b061489c18684b4b9d6ea146eab5acb2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca76c495458a47e3ab5a53e6fb06f460"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n      (position_embeddings): Embedding(258, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=1930, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Tokenizer\ntrain_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=10)\nval_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=10)\ntest_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=10)\n\n# Length check\nprint(len(train_texts), len(val_texts), len(test_texts))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:00.620779Z","iopub.execute_input":"2024-06-27T15:37:00.621063Z","iopub.status.idle":"2024-06-27T15:37:12.343218Z","shell.execute_reply.started":"2024-06-27T15:37:00.621038Z","shell.execute_reply":"2024-06-27T15:37:12.342312Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"67287 14418 14420\n","output_type":"stream"}]},{"cell_type":"code","source":"class DataLoader(Dataset):\n    \"\"\"\n    Custom Dataset class for handling tokenized text data and corresponding labels.\n    Inherits from torch.utils.data.Dataset.\n    \"\"\"\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        # Retrieve tokenized data for the given index\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        # Add the label for the given index to the item dictionary\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.344439Z","iopub.execute_input":"2024-06-27T15:37:12.344737Z","iopub.status.idle":"2024-06-27T15:37:12.351603Z","shell.execute_reply.started":"2024-06-27T15:37:12.344710Z","shell.execute_reply":"2024-06-27T15:37:12.350692Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(train_encodings.keys())","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.352801Z","iopub.execute_input":"2024-06-27T15:37:12.353146Z","iopub.status.idle":"2024-06-27T15:37:12.359985Z","shell.execute_reply.started":"2024-06-27T15:37:12.353121Z","shell.execute_reply":"2024-06-27T15:37:12.359077Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n","output_type":"stream"}]},{"cell_type":"code","source":"len(train_encodings['input_ids'][0]), len(train_encodings['token_type_ids'][0]), len(train_encodings['attention_mask'][0])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.361123Z","iopub.execute_input":"2024-06-27T15:37:12.361434Z","iopub.status.idle":"2024-06-27T15:37:12.368370Z","shell.execute_reply.started":"2024-06-27T15:37:12.361399Z","shell.execute_reply":"2024-06-27T15:37:12.367474Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(10, 10, 10)"},"metadata":{}}]},{"cell_type":"code","source":"print(train_encodings['input_ids'][0])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.369425Z","iopub.execute_input":"2024-06-27T15:37:12.369656Z","iopub.status.idle":"2024-06-27T15:37:12.377455Z","shell.execute_reply.started":"2024-06-27T15:37:12.369636Z","shell.execute_reply":"2024-06-27T15:37:12.376631Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"[0, 797, 6829, 5659, 542, 797, 6829, 5659, 5438, 2]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_labels[0])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.378617Z","iopub.execute_input":"2024-06-27T15:37:12.378988Z","iopub.status.idle":"2024-06-27T15:37:12.385266Z","shell.execute_reply.started":"2024-06-27T15:37:12.378953Z","shell.execute_reply":"2024-06-27T15:37:12.384477Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"50\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_encodings, train_labels)\n\nval_dataloader = DataLoader(val_encodings, val_labels)\n\ntest_dataset = DataLoader(test_encodings, test_labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.386349Z","iopub.execute_input":"2024-06-27T15:37:12.386662Z","iopub.status.idle":"2024-06-27T15:37:12.393253Z","shell.execute_reply.started":"2024-06-27T15:37:12.386640Z","shell.execute_reply":"2024-06-27T15:37:12.392347Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_dataloader[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.394283Z","iopub.execute_input":"2024-06-27T15:37:12.394645Z","iopub.status.idle":"2024-06-27T15:37:12.404753Z","shell.execute_reply.started":"2024-06-27T15:37:12.394616Z","shell.execute_reply":"2024-06-27T15:37:12.403846Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([   0,  797, 6829, 5659,  542,  797, 6829, 5659, 5438,    2]),\n 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n 'labels': tensor(50)}"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\ndef compute_metrics(pred):\n    # Extract true labels from the input object\n    labels = pred.label_ids\n    \n    # Obtain predicted class labels by finding the column index with the maximum probability\n    preds = pred.predictions.argmax(-1)\n    \n    # Compute macro precision, recall, and F1 score using sklearn's precision_recall_fscore_support function\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n    \n    # Calculate the accuracy score using sklearn's accuracy_score function\n    acc = accuracy_score(labels, preds)\n    \n    # Return the computed metrics as a dictionary\n    return {\n        'Accuracy': acc,\n        'F1': f1,\n        'Precision': precision,\n        'Recall': recall\n    }","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.405780Z","iopub.execute_input":"2024-06-27T15:37:12.406040Z","iopub.status.idle":"2024-06-27T15:37:12.816972Z","shell.execute_reply.started":"2024-06-27T15:37:12.406019Z","shell.execute_reply":"2024-06-27T15:37:12.816200Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import warnings\nfrom sklearn.exceptions import UndefinedMetricWarning\n\nwarnings.filterwarnings(\"ignore\", message=\"Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\")\nwarnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.817994Z","iopub.execute_input":"2024-06-27T15:37:12.818607Z","iopub.status.idle":"2024-06-27T15:37:12.823935Z","shell.execute_reply.started":"2024-06-27T15:37:12.818579Z","shell.execute_reply":"2024-06-27T15:37:12.822958Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    # The output directory where the model predictions and checkpoints will be written\n    output_dir='./pho-bert-classification', \n    do_train=True,\n    do_eval=True,\n    # The number of epochs, defaults to 3.0 \n    num_train_epochs= 15,              \n    per_device_train_batch_size=32,  \n    per_device_eval_batch_size=32,\n    # Number of steps used for a linear warmup\n    warmup_steps=500,                \n    weight_decay=0.01,\n    logging_strategy='steps',\n    # TensorBoard log directory                 \n    logging_dir='./multi-class-logs',            \n    logging_steps=300,  \n    evaluation_strategy=\"steps\",\n    eval_steps=300,\n    save_strategy=\"steps\", \n    save_steps=300,  \n    save_total_limit=2,  \n    fp16=True,\n    load_best_model_at_end=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.825075Z","iopub.execute_input":"2024-06-27T15:37:12.825360Z","iopub.status.idle":"2024-06-27T15:37:12.863826Z","shell.execute_reply.started":"2024-06-27T15:37:12.825329Z","shell.execute_reply":"2024-06-27T15:37:12.862938Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Trainer(\n    # the pre-trained model that will be fine-tuned \n    model=model,\n     # training arguments that we defined above                        \n    args=training_args,                 \n    train_dataset=train_dataloader,         \n    eval_dataset=val_dataloader,            \n    compute_metrics= compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:12.865132Z","iopub.execute_input":"2024-06-27T15:37:12.865603Z","iopub.status.idle":"2024-06-27T15:37:13.484808Z","shell.execute_reply.started":"2024-06-27T15:37:12.865570Z","shell.execute_reply":"2024-06-27T15:37:13.484059Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:37:13.485816Z","iopub.execute_input":"2024-06-27T15:37:13.486061Z","iopub.status.idle":"2024-06-27T17:00:20.395353Z","shell.execute_reply.started":"2024-06-27T15:37:13.486039Z","shell.execute_reply":"2024-06-27T17:00:20.394521Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240627_153941-sdrf57js</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/vuzle/huggingface/runs/sdrf57js' target=\"_blank\">./pho-bert-classification</a></strong> to <a href='https://wandb.ai/vuzle/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/vuzle/huggingface' target=\"_blank\">https://wandb.ai/vuzle/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/vuzle/huggingface/runs/sdrf57js' target=\"_blank\">https://wandb.ai/vuzle/huggingface/runs/sdrf57js</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='15780' max='15780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [15780/15780 1:20:17, Epoch 15/15]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>300</td>\n      <td>7.563000</td>\n      <td>7.498380</td>\n      <td>0.004023</td>\n      <td>0.000823</td>\n      <td>0.000826</td>\n      <td>0.003966</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>7.324400</td>\n      <td>7.008364</td>\n      <td>0.051880</td>\n      <td>0.025118</td>\n      <td>0.028779</td>\n      <td>0.054877</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>6.753300</td>\n      <td>6.357321</td>\n      <td>0.084478</td>\n      <td>0.044746</td>\n      <td>0.049938</td>\n      <td>0.092915</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>6.091800</td>\n      <td>5.735357</td>\n      <td>0.121445</td>\n      <td>0.071234</td>\n      <td>0.078728</td>\n      <td>0.131632</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>5.514100</td>\n      <td>5.213038</td>\n      <td>0.159662</td>\n      <td>0.098046</td>\n      <td>0.101788</td>\n      <td>0.176692</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>5.036900</td>\n      <td>4.760133</td>\n      <td>0.195034</td>\n      <td>0.132093</td>\n      <td>0.138870</td>\n      <td>0.212535</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>4.646000</td>\n      <td>4.382796</td>\n      <td>0.222638</td>\n      <td>0.154842</td>\n      <td>0.163100</td>\n      <td>0.240064</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>4.162000</td>\n      <td>4.041720</td>\n      <td>0.244763</td>\n      <td>0.177935</td>\n      <td>0.187197</td>\n      <td>0.262611</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>3.887400</td>\n      <td>3.762632</td>\n      <td>0.281246</td>\n      <td>0.207547</td>\n      <td>0.213611</td>\n      <td>0.298023</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>3.658600</td>\n      <td>3.524655</td>\n      <td>0.301567</td>\n      <td>0.232616</td>\n      <td>0.240437</td>\n      <td>0.319848</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>3.364500</td>\n      <td>3.320536</td>\n      <td>0.317312</td>\n      <td>0.248418</td>\n      <td>0.260661</td>\n      <td>0.336622</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>3.128600</td>\n      <td>3.137150</td>\n      <td>0.336801</td>\n      <td>0.269547</td>\n      <td>0.286265</td>\n      <td>0.355727</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>2.987800</td>\n      <td>2.994285</td>\n      <td>0.353308</td>\n      <td>0.291759</td>\n      <td>0.311862</td>\n      <td>0.373119</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>2.873000</td>\n      <td>2.869108</td>\n      <td>0.366001</td>\n      <td>0.305648</td>\n      <td>0.323969</td>\n      <td>0.383142</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>2.634500</td>\n      <td>2.772468</td>\n      <td>0.374948</td>\n      <td>0.314554</td>\n      <td>0.337588</td>\n      <td>0.389578</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>2.563400</td>\n      <td>2.678829</td>\n      <td>0.390484</td>\n      <td>0.336829</td>\n      <td>0.358111</td>\n      <td>0.407037</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>2.459600</td>\n      <td>2.604360</td>\n      <td>0.392079</td>\n      <td>0.343358</td>\n      <td>0.372806</td>\n      <td>0.411334</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>2.333500</td>\n      <td>2.542617</td>\n      <td>0.406090</td>\n      <td>0.350971</td>\n      <td>0.372951</td>\n      <td>0.419016</td>\n    </tr>\n    <tr>\n      <td>5700</td>\n      <td>2.230400</td>\n      <td>2.483568</td>\n      <td>0.409072</td>\n      <td>0.357813</td>\n      <td>0.379524</td>\n      <td>0.425023</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>2.189900</td>\n      <td>2.429228</td>\n      <td>0.420239</td>\n      <td>0.373004</td>\n      <td>0.401263</td>\n      <td>0.432972</td>\n    </tr>\n    <tr>\n      <td>6300</td>\n      <td>2.144000</td>\n      <td>2.391753</td>\n      <td>0.421002</td>\n      <td>0.376019</td>\n      <td>0.410428</td>\n      <td>0.433862</td>\n    </tr>\n    <tr>\n      <td>6600</td>\n      <td>1.997400</td>\n      <td>2.352993</td>\n      <td>0.429533</td>\n      <td>0.382098</td>\n      <td>0.406597</td>\n      <td>0.441039</td>\n    </tr>\n    <tr>\n      <td>6900</td>\n      <td>1.985100</td>\n      <td>2.325475</td>\n      <td>0.427036</td>\n      <td>0.383855</td>\n      <td>0.409625</td>\n      <td>0.439429</td>\n    </tr>\n    <tr>\n      <td>7200</td>\n      <td>1.963100</td>\n      <td>2.291819</td>\n      <td>0.429533</td>\n      <td>0.390843</td>\n      <td>0.419267</td>\n      <td>0.441707</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>1.846600</td>\n      <td>2.274659</td>\n      <td>0.433902</td>\n      <td>0.393202</td>\n      <td>0.423155</td>\n      <td>0.444877</td>\n    </tr>\n    <tr>\n      <td>7800</td>\n      <td>1.808600</td>\n      <td>2.257437</td>\n      <td>0.439451</td>\n      <td>0.398421</td>\n      <td>0.426991</td>\n      <td>0.450494</td>\n    </tr>\n    <tr>\n      <td>8100</td>\n      <td>1.792800</td>\n      <td>2.238758</td>\n      <td>0.437786</td>\n      <td>0.401835</td>\n      <td>0.436820</td>\n      <td>0.451238</td>\n    </tr>\n    <tr>\n      <td>8400</td>\n      <td>1.787300</td>\n      <td>2.208481</td>\n      <td>0.443959</td>\n      <td>0.406124</td>\n      <td>0.435314</td>\n      <td>0.454343</td>\n    </tr>\n    <tr>\n      <td>8700</td>\n      <td>1.654900</td>\n      <td>2.210768</td>\n      <td>0.441046</td>\n      <td>0.402658</td>\n      <td>0.429144</td>\n      <td>0.450054</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>1.662700</td>\n      <td>2.187226</td>\n      <td>0.447427</td>\n      <td>0.411797</td>\n      <td>0.437086</td>\n      <td>0.459199</td>\n    </tr>\n    <tr>\n      <td>9300</td>\n      <td>1.665500</td>\n      <td>2.177855</td>\n      <td>0.445693</td>\n      <td>0.412897</td>\n      <td>0.441826</td>\n      <td>0.457144</td>\n    </tr>\n    <tr>\n      <td>9600</td>\n      <td>1.625800</td>\n      <td>2.169132</td>\n      <td>0.450479</td>\n      <td>0.416233</td>\n      <td>0.446971</td>\n      <td>0.460833</td>\n    </tr>\n    <tr>\n      <td>9900</td>\n      <td>1.550500</td>\n      <td>2.169214</td>\n      <td>0.443265</td>\n      <td>0.412400</td>\n      <td>0.440022</td>\n      <td>0.456231</td>\n    </tr>\n    <tr>\n      <td>10200</td>\n      <td>1.552200</td>\n      <td>2.155730</td>\n      <td>0.447496</td>\n      <td>0.415680</td>\n      <td>0.443929</td>\n      <td>0.458226</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>1.564000</td>\n      <td>2.136694</td>\n      <td>0.455126</td>\n      <td>0.423927</td>\n      <td>0.454827</td>\n      <td>0.464808</td>\n    </tr>\n    <tr>\n      <td>10800</td>\n      <td>1.461700</td>\n      <td>2.142002</td>\n      <td>0.448537</td>\n      <td>0.419223</td>\n      <td>0.449946</td>\n      <td>0.457859</td>\n    </tr>\n    <tr>\n      <td>11100</td>\n      <td>1.476900</td>\n      <td>2.136418</td>\n      <td>0.453600</td>\n      <td>0.424181</td>\n      <td>0.452072</td>\n      <td>0.462432</td>\n    </tr>\n    <tr>\n      <td>11400</td>\n      <td>1.478400</td>\n      <td>2.131004</td>\n      <td>0.450964</td>\n      <td>0.423735</td>\n      <td>0.448171</td>\n      <td>0.463844</td>\n    </tr>\n    <tr>\n      <td>11700</td>\n      <td>1.432700</td>\n      <td>2.129603</td>\n      <td>0.453600</td>\n      <td>0.425327</td>\n      <td>0.451008</td>\n      <td>0.463718</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>1.388600</td>\n      <td>2.129586</td>\n      <td>0.452143</td>\n      <td>0.423842</td>\n      <td>0.449673</td>\n      <td>0.462870</td>\n    </tr>\n    <tr>\n      <td>12300</td>\n      <td>1.407800</td>\n      <td>2.122313</td>\n      <td>0.453322</td>\n      <td>0.426751</td>\n      <td>0.456837</td>\n      <td>0.464570</td>\n    </tr>\n    <tr>\n      <td>12600</td>\n      <td>1.404500</td>\n      <td>2.119130</td>\n      <td>0.453600</td>\n      <td>0.428069</td>\n      <td>0.457053</td>\n      <td>0.463533</td>\n    </tr>\n    <tr>\n      <td>12900</td>\n      <td>1.334000</td>\n      <td>2.122989</td>\n      <td>0.454987</td>\n      <td>0.429009</td>\n      <td>0.460146</td>\n      <td>0.464214</td>\n    </tr>\n    <tr>\n      <td>13200</td>\n      <td>1.346900</td>\n      <td>2.117332</td>\n      <td>0.453530</td>\n      <td>0.426591</td>\n      <td>0.454139</td>\n      <td>0.462198</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>1.351000</td>\n      <td>2.112800</td>\n      <td>0.454016</td>\n      <td>0.429475</td>\n      <td>0.455184</td>\n      <td>0.464445</td>\n    </tr>\n    <tr>\n      <td>13800</td>\n      <td>1.322200</td>\n      <td>2.117969</td>\n      <td>0.452906</td>\n      <td>0.427876</td>\n      <td>0.452246</td>\n      <td>0.463099</td>\n    </tr>\n    <tr>\n      <td>14100</td>\n      <td>1.290800</td>\n      <td>2.113054</td>\n      <td>0.453114</td>\n      <td>0.429007</td>\n      <td>0.454306</td>\n      <td>0.463918</td>\n    </tr>\n    <tr>\n      <td>14400</td>\n      <td>1.296900</td>\n      <td>2.111303</td>\n      <td>0.453738</td>\n      <td>0.430125</td>\n      <td>0.455640</td>\n      <td>0.464679</td>\n    </tr>\n    <tr>\n      <td>14700</td>\n      <td>1.312100</td>\n      <td>2.109722</td>\n      <td>0.454432</td>\n      <td>0.430934</td>\n      <td>0.454473</td>\n      <td>0.465067</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>1.260600</td>\n      <td>2.110191</td>\n      <td>0.454155</td>\n      <td>0.431102</td>\n      <td>0.454277</td>\n      <td>0.464266</td>\n    </tr>\n    <tr>\n      <td>15300</td>\n      <td>1.255100</td>\n      <td>2.110785</td>\n      <td>0.452975</td>\n      <td>0.430138</td>\n      <td>0.452937</td>\n      <td>0.463299</td>\n    </tr>\n    <tr>\n      <td>15600</td>\n      <td>1.273600</td>\n      <td>2.110539</td>\n      <td>0.454848</td>\n      <td>0.432095</td>\n      <td>0.455322</td>\n      <td>0.465043</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=15780, training_loss=2.5069257777302285, metrics={'train_runtime': 4986.4916, 'train_samples_per_second': 202.408, 'train_steps_per_second': 3.165, 'total_flos': 5276490824424600.0, 'train_loss': 2.5069257777302285, 'epoch': 15.0})"},"metadata":{}}]},{"cell_type":"code","source":"q=[trainer.evaluate(eval_dataset=df_org) for df_org in [train_dataloader, val_dataloader, test_dataset]]\n\npd.DataFrame(q, index=[\"train\",\"val\",\"test\"]).iloc[:,:5]","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:00:20.396454Z","iopub.execute_input":"2024-06-27T17:00:20.396812Z","iopub.status.idle":"2024-06-27T17:02:14.834493Z","shell.execute_reply.started":"2024-06-27T17:00:20.396779Z","shell.execute_reply":"2024-06-27T17:02:14.833359Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1504' max='1052' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1052/1052 01:54]\n    </div>\n    "},"metadata":{}},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"       eval_loss  eval_Accuracy   eval_F1  eval_Precision  eval_Recall\ntrain   1.125566       0.666473  0.653848        0.701755     0.663133\nval     2.109722       0.454432  0.430934        0.454473     0.465067\ntest    2.080833       0.462691  0.432079        0.460369     0.464698","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eval_loss</th>\n      <th>eval_Accuracy</th>\n      <th>eval_F1</th>\n      <th>eval_Precision</th>\n      <th>eval_Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>train</th>\n      <td>1.125566</td>\n      <td>0.666473</td>\n      <td>0.653848</td>\n      <td>0.701755</td>\n      <td>0.663133</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>2.109722</td>\n      <td>0.454432</td>\n      <td>0.430934</td>\n      <td>0.454473</td>\n      <td>0.465067</td>\n    </tr>\n    <tr>\n      <th>test</th>\n      <td>2.080833</td>\n      <td>0.462691</td>\n      <td>0.432079</td>\n      <td>0.460369</td>\n      <td>0.464698</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def predict(text):\n    \"\"\"\n    Predicts the class label for a given input text\n\n    Args:\n        text (str): The input text for which the class label needs to be predicted.\n\n    Returns:\n        probs (torch.Tensor): Class probabilities for the input text.\n        pred_label_idx (torch.Tensor): The index of the predicted class label.\n        pred_label (str): The predicted class label.\n    \"\"\"\n    # Tokenize the input text and move tensors to the GPU if available\n    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(\"cuda\")\n\n    # Get model output (logits)\n    outputs = model(**inputs)\n\n    probs = outputs[0].softmax(1)\n    \"\"\" Explanation outputs: The BERT model returns a tuple containing the output logits (and possibly other elements depending on the model configuration). In this case, the output logits are the first element in the tuple, which is why we access it using outputs[0].\n\n    outputs[0]: This is a tensor containing the raw output logits for each class. The shape of the tensor is (batch_size, num_classes) where batch_size is the number of input samples (in this case, 1, as we are predicting for a single input text) and num_classes is the number of target classes.\n\n    softmax(1): The softmax function is applied along dimension 1 (the class dimension) to convert the raw logits into class probabilities. Softmax normalizes the logits so that they sum to 1, making them interpretable as probabilities. \"\"\"\n    \n    pred_label_idx = probs.argmax()\n    \n    pred_label = model.config.id2label[pred_label_idx.item()]\n\n    return probs, pred_label_idx, pred_label","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:02:14.841820Z","iopub.execute_input":"2024-06-27T17:02:14.842471Z","iopub.status.idle":"2024-06-27T17:02:14.852929Z","shell.execute_reply.started":"2024-06-27T17:02:14.842428Z","shell.execute_reply":"2024-06-27T17:02:14.851681Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Test with a an example text in Turkish\ntext = \"gh·∫ø hq\"\n# \"Machine Learning itself is moving towards more and more automated\"\npredict(text)[2]","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:02:14.854077Z","iopub.execute_input":"2024-06-27T17:02:14.854449Z","iopub.status.idle":"2024-06-27T17:02:14.913050Z","shell.execute_reply.started":"2024-06-27T17:02:14.854421Z","shell.execute_reply":"2024-06-27T17:02:14.912088Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"'gh·∫ø vƒÉn ph√≤ng'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Save model for inference","metadata":{}},{"cell_type":"code","source":"model_path = \"pho-bert-classification\"\ntrainer.save_model(model_path)\ntokenizer.save_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:02:14.914324Z","iopub.execute_input":"2024-06-27T17:02:14.914866Z","iopub.status.idle":"2024-06-27T17:02:16.036227Z","shell.execute_reply.started":"2024-06-27T17:02:14.914833Z","shell.execute_reply":"2024-06-27T17:02:16.035159Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"('pho-bert-classification/tokenizer_config.json',\n 'pho-bert-classification/special_tokens_map.json',\n 'pho-bert-classification/vocab.txt',\n 'pho-bert-classification/bpe.codes',\n 'pho-bert-classification/added_tokens.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Re-Load saved model for inference","metadata":{}},{"cell_type":"code","source":"model_path = \"pho-bert-classification\"","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:02:16.037567Z","iopub.execute_input":"2024-06-27T17:02:16.037931Z","iopub.status.idle":"2024-06-27T17:02:16.043081Z","shell.execute_reply.started":"2024-06-27T17:02:16.037896Z","shell.execute_reply":"2024-06-27T17:02:16.041999Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Load model and tokenizer\nmodel = RobertaForSequenceClassification.from_pretrained(model_path)\ntokenizer= AutoTokenizer.from_pretrained(model_path)\n# Switch model to device (CPU/GPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:02:16.044462Z","iopub.execute_input":"2024-06-27T17:02:16.044899Z","iopub.status.idle":"2024-06-27T17:02:16.580152Z","shell.execute_reply.started":"2024-06-27T17:02:16.044863Z","shell.execute_reply":"2024-06-27T17:02:16.579131Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n      (position_embeddings): Embedding(258, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=1930, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"#%%time\n# Apply predict function to each row in the Name column\n#df_org['pred_label'] = df_org['Name'].apply(lambda x: predict(x)[2])","metadata":{"execution":{"iopub.status.busy":"2024-06-26T10:58:31.565322Z","iopub.execute_input":"2024-06-26T10:58:31.565938Z","iopub.status.idle":"2024-06-26T11:17:53.644302Z","shell.execute_reply.started":"2024-06-26T10:58:31.565903Z","shell.execute_reply":"2024-06-26T11:17:53.643045Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"#df_org","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:21:54.101345Z","iopub.execute_input":"2024-06-26T11:21:54.101749Z","iopub.status.idle":"2024-06-26T11:21:54.122873Z","shell.execute_reply.started":"2024-06-26T11:21:54.101714Z","shell.execute_reply":"2024-06-26T11:21:54.121882Z"},"trusted":true},"execution_count":117,"outputs":[{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"                             Label  \\\n0      bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i   \n1      bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i   \n2      bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i   \n3      bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i   \n4      bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i   \n...                            ...   \n96072                  l·∫Øc tay nam   \n96073                  l·∫Øc tay nam   \n96074                  l·∫Øc tay nam   \n96075                  l·∫Øc tay nam   \n96076                  l·∫Øc tay nam   \n\n                                                    Name  labels  \\\n0                              ·ªëp l∆∞ng carbon iphone x√°m       0   \n1            ·ªëp l∆∞ng lenovo vibe nh·ª±a tpu ch·ªëng tr∆°n m√†u       0   \n2      ·ªëp l∆∞ng note neo tr√°ng g∆∞∆°ng vi·ªÅn kim lo·∫°i m√†u...       0   \n3                                 bao da ƒë·ª±ng ƒëi·ªán tho·∫°i       0   \n4                       ·ªëp l∆∞ng viva flex iphone m√†u ƒëen       0   \n...                                                  ...     ...   \n96072                             v√≤ng tay handmade tank    1927   \n96073             v√≤ng tay nam m√†u k·∫øt h·ª£p v√†ng b·∫°c toma    1927   \n96074                          v√≤ng tay nam m√†u b·∫°c toma    1927   \n96075                            l·∫Øc nam inox th·ªùi trang    1927   \n96076                                       v√≤ng tay nam    1927   \n\n                        pred_label  \n0      bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i  \n1      bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i  \n2      bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i  \n3      bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i  \n4      bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i  \n...                            ...  \n96072                   l·∫Øc tay n·ªØ  \n96073                  l·∫Øc tay nam  \n96074                  l·∫Øc tay nam  \n96075                  l·∫Øc tay nam  \n96076                  l·∫Øc tay nam  \n\n[95967 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Name</th>\n      <th>labels</th>\n      <th>pred_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n      <td>·ªëp l∆∞ng carbon iphone x√°m</td>\n      <td>0</td>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n      <td>·ªëp l∆∞ng lenovo vibe nh·ª±a tpu ch·ªëng tr∆°n m√†u</td>\n      <td>0</td>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n      <td>·ªëp l∆∞ng note neo tr√°ng g∆∞∆°ng vi·ªÅn kim lo·∫°i m√†u...</td>\n      <td>0</td>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n      <td>bao da ƒë·ª±ng ƒëi·ªán tho·∫°i</td>\n      <td>0</td>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n      <td>·ªëp l∆∞ng viva flex iphone m√†u ƒëen</td>\n      <td>0</td>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>96072</th>\n      <td>l·∫Øc tay nam</td>\n      <td>v√≤ng tay handmade tank</td>\n      <td>1927</td>\n      <td>l·∫Øc tay n·ªØ</td>\n    </tr>\n    <tr>\n      <th>96073</th>\n      <td>l·∫Øc tay nam</td>\n      <td>v√≤ng tay nam m√†u k·∫øt h·ª£p v√†ng b·∫°c toma</td>\n      <td>1927</td>\n      <td>l·∫Øc tay nam</td>\n    </tr>\n    <tr>\n      <th>96074</th>\n      <td>l·∫Øc tay nam</td>\n      <td>v√≤ng tay nam m√†u b·∫°c toma</td>\n      <td>1927</td>\n      <td>l·∫Øc tay nam</td>\n    </tr>\n    <tr>\n      <th>96075</th>\n      <td>l·∫Øc tay nam</td>\n      <td>l·∫Øc nam inox th·ªùi trang</td>\n      <td>1927</td>\n      <td>l·∫Øc tay nam</td>\n    </tr>\n    <tr>\n      <th>96076</th>\n      <td>l·∫Øc tay nam</td>\n      <td>v√≤ng tay nam</td>\n      <td>1927</td>\n      <td>l·∫Øc tay nam</td>\n    </tr>\n  </tbody>\n</table>\n<p>95967 rows √ó 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Create DataFrame containing only the observations where Label != pred_label\n#df_mismatch = df_org[df_org['Label'] != df_org['pred_label']]","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:28:59.390574Z","iopub.execute_input":"2024-06-26T11:28:59.391024Z","iopub.status.idle":"2024-06-26T11:28:59.423923Z","shell.execute_reply.started":"2024-06-26T11:28:59.390994Z","shell.execute_reply":"2024-06-26T11:28:59.422913Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"#df_mismatch","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:29:11.773148Z","iopub.execute_input":"2024-06-26T11:29:11.773989Z","iopub.status.idle":"2024-06-26T11:29:11.790979Z","shell.execute_reply.started":"2024-06-26T11:29:11.773957Z","shell.execute_reply":"2024-06-26T11:29:11.789823Z"},"trusted":true},"execution_count":121,"outputs":[{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"                             Label  \\\n28     bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i   \n46     bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i   \n51             b√†n gh·∫ø ph√≤ng kh√°ch   \n55             b√†n gh·∫ø ph√≤ng kh√°ch   \n56             b√†n gh·∫ø ph√≤ng kh√°ch   \n...                            ...   \n96049                  l·∫Øc tay nam   \n96050                  l·∫Øc tay nam   \n96066                  l·∫Øc tay nam   \n96069                  l·∫Øc tay nam   \n96072                  l·∫Øc tay nam   \n\n                                                    Name  labels  \\\n28                    ·ªëp g∆∞∆°ng trang ƒëi·ªÉm ƒë√≠nh ƒë√° iphone       0   \n46                         ·ªëp d·∫ªo doanh nh√¢n xi b√≥ng ƒë·∫ßu       0   \n51                               salon h∆∞∆°ng voi tay m√≥n       1   \n55                       b√†n gh·∫ø minh qu·ªëc ch·∫°m h·ªìng trƒ©       1   \n56                          tr∆∞·ªùng k·ªâ ng≈© s∆°n kh·∫£m ·ªëc c≈©       1   \n...                                                  ...     ...   \n96049  l·∫Øc tay m·∫° v√†ng phong c√°ch √¢u m·ªπ k√®m v√≤ng tay ...    1927   \n96050    l·∫Øc tay nam d√¢y x√≠ch ch·∫•t li·ªáu th√©p titan ko r·ªâ    1927   \n96066  l·∫Øc tay m·∫° b·∫°c phong c√°ch √¢u m·ªπ k√®m v√≤ng tay t...    1927   \n96069  l·∫Øc tay m·∫° v√†ng phong c√°ch √¢u m·ªπ k√®m v√≤ng tay ...    1927   \n96072                             v√≤ng tay handmade tank    1927   \n\n                   pred_label  \n28           g∆∞∆°ng trang ƒëi·ªÉm  \n46            gƒÉng tay b·∫£o h·ªô  \n51                 sofa salon  \n55           b√†n gh·∫ø s√¢n v∆∞·ªùn  \n56     gh·∫ø h·ªôi tr∆∞·ªùng r·∫°p h√°t  \n...                       ...  \n96049              l·∫Øc tay n·ªØ  \n96050                    x√≠ch  \n96066              l·∫Øc tay n·ªØ  \n96069              l·∫Øc tay n·ªØ  \n96072              l·∫Øc tay n·ªØ  \n\n[40149 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Name</th>\n      <th>labels</th>\n      <th>pred_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>28</th>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n      <td>·ªëp g∆∞∆°ng trang ƒëi·ªÉm ƒë√≠nh ƒë√° iphone</td>\n      <td>0</td>\n      <td>g∆∞∆°ng trang ƒëi·ªÉm</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>bao ƒë·ª±ng ·ªëp l∆∞ng ƒëi·ªán tho·∫°i</td>\n      <td>·ªëp d·∫ªo doanh nh√¢n xi b√≥ng ƒë·∫ßu</td>\n      <td>0</td>\n      <td>gƒÉng tay b·∫£o h·ªô</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>b√†n gh·∫ø ph√≤ng kh√°ch</td>\n      <td>salon h∆∞∆°ng voi tay m√≥n</td>\n      <td>1</td>\n      <td>sofa salon</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>b√†n gh·∫ø ph√≤ng kh√°ch</td>\n      <td>b√†n gh·∫ø minh qu·ªëc ch·∫°m h·ªìng trƒ©</td>\n      <td>1</td>\n      <td>b√†n gh·∫ø s√¢n v∆∞·ªùn</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>b√†n gh·∫ø ph√≤ng kh√°ch</td>\n      <td>tr∆∞·ªùng k·ªâ ng≈© s∆°n kh·∫£m ·ªëc c≈©</td>\n      <td>1</td>\n      <td>gh·∫ø h·ªôi tr∆∞·ªùng r·∫°p h√°t</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>96049</th>\n      <td>l·∫Øc tay nam</td>\n      <td>l·∫Øc tay m·∫° v√†ng phong c√°ch √¢u m·ªπ k√®m v√≤ng tay ...</td>\n      <td>1927</td>\n      <td>l·∫Øc tay n·ªØ</td>\n    </tr>\n    <tr>\n      <th>96050</th>\n      <td>l·∫Øc tay nam</td>\n      <td>l·∫Øc tay nam d√¢y x√≠ch ch·∫•t li·ªáu th√©p titan ko r·ªâ</td>\n      <td>1927</td>\n      <td>x√≠ch</td>\n    </tr>\n    <tr>\n      <th>96066</th>\n      <td>l·∫Øc tay nam</td>\n      <td>l·∫Øc tay m·∫° b·∫°c phong c√°ch √¢u m·ªπ k√®m v√≤ng tay t...</td>\n      <td>1927</td>\n      <td>l·∫Øc tay n·ªØ</td>\n    </tr>\n    <tr>\n      <th>96069</th>\n      <td>l·∫Øc tay nam</td>\n      <td>l·∫Øc tay m·∫° v√†ng phong c√°ch √¢u m·ªπ k√®m v√≤ng tay ...</td>\n      <td>1927</td>\n      <td>l·∫Øc tay n·ªØ</td>\n    </tr>\n    <tr>\n      <th>96072</th>\n      <td>l·∫Øc tay nam</td>\n      <td>v√≤ng tay handmade tank</td>\n      <td>1927</td>\n      <td>l·∫Øc tay n·ªØ</td>\n    </tr>\n  </tbody>\n</table>\n<p>40149 rows √ó 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Save the resulting DataFrame to a CSV file\n#df_mismatch_check = df_mismatch[['Name','Label','pred_label']]","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:37:41.681822Z","iopub.execute_input":"2024-06-26T11:37:41.682195Z","iopub.status.idle":"2024-06-26T11:37:41.695809Z","shell.execute_reply.started":"2024-06-26T11:37:41.682165Z","shell.execute_reply":"2024-06-26T11:37:41.694538Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"#df_mismatch_check.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:39:30.129400Z","iopub.execute_input":"2024-06-26T11:39:30.129797Z","iopub.status.idle":"2024-06-26T11:39:30.140487Z","shell.execute_reply.started":"2024-06-26T11:39:30.129754Z","shell.execute_reply":"2024-06-26T11:39:30.139015Z"},"trusted":true},"execution_count":132,"outputs":[{"execution_count":132,"output_type":"execute_result","data":{"text/plain":"(40149, 3)"},"metadata":{}}]},{"cell_type":"code","source":"# L∆∞u DataFrame v√†o t·ªáp CSV\n#df_mismatch_check.to_csv('df_mismatch_check.csv', encoding = 'utf-8', index=False)\n\n# T·∫°o li√™n k·∫øt t·∫£i v·ªÅ\n#from IPython.display import FileLink\n\n#FileLink('df_mismatch_check.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:37:59.814738Z","iopub.execute_input":"2024-06-26T11:37:59.815502Z","iopub.status.idle":"2024-06-26T11:38:00.050158Z","shell.execute_reply.started":"2024-06-26T11:37:59.815469Z","shell.execute_reply":"2024-06-26T11:38:00.048395Z"},"trusted":true},"execution_count":131,"outputs":[{"execution_count":131,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/df_mismatch_check.csv","text/html":"<a href='df_mismatch_check.csv' target='_blank'>df_mismatch_check.csv</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"import shutil\nfrom IPython.display import FileLink\n\n# N√©n th∆∞ m·ª•c th√†nh t·ªáp ZIP\nshutil.make_archive('pho-bert-classification', 'zip', 'pho-bert-classification')\n\n# T·∫°o li√™n k·∫øt t·∫£i v·ªÅ\nFileLink('pho-bert-classification.zip')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:02:16.581945Z","iopub.execute_input":"2024-06-27T17:02:16.582222Z","iopub.status.idle":"2024-06-27T17:05:11.859705Z","shell.execute_reply.started":"2024-06-27T17:02:16.582196Z","shell.execute_reply":"2024-06-27T17:05:11.858383Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/pho-bert-classification.zip","text/html":"<a href='pho-bert-classification.zip' target='_blank'>pho-bert-classification.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"model = RobertaForSequenceClassification.from_pretrained(model_path)\ntokenizer= AutoTokenizer.from_pretrained(model_path)\nnlp= pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:10:42.010837Z","iopub.execute_input":"2024-06-27T17:10:42.011200Z","iopub.status.idle":"2024-06-27T17:10:42.423296Z","shell.execute_reply.started":"2024-06-27T17:10:42.011170Z","shell.execute_reply":"2024-06-27T17:10:42.422050Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"nlp(\"·ªëp g∆∞∆°ng trang ƒëi·ªÉm ƒë√≠nh ƒë√° iphone\") ","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:10:43.582971Z","iopub.execute_input":"2024-06-27T17:10:43.583342Z","iopub.status.idle":"2024-06-27T17:10:43.744676Z","shell.execute_reply.started":"2024-06-27T17:10:43.583288Z","shell.execute_reply":"2024-06-27T17:10:43.743042Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"[{'label': 'g∆∞∆°ng trang ƒëi·ªÉm', 'score': 0.44541189074516296}]"},"metadata":{}}]}]}