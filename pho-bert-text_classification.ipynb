{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8744873,"sourceType":"datasetVersion","datasetId":5250902}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-21T12:35:29.968855Z","iopub.execute_input":"2024-06-21T12:35:29.970218Z","iopub.status.idle":"2024-06-21T12:35:30.372607Z","shell.execute_reply.started":"2024-06-21T12:35:29.970177Z","shell.execute_reply":"2024-06-21T12:35:30.371750Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/cleaned-data/cleaned_data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch, os\nimport pandas as pd\nfrom transformers import pipeline, BertForSequenceClassification, BertTokenizerFast\nfrom transformers import RobertaForSequenceClassification, AutoTokenizer\nfrom torch.utils.data import Dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:35:30.374385Z","iopub.execute_input":"2024-06-21T12:35:30.374760Z","iopub.status.idle":"2024-06-21T12:35:58.208715Z","shell.execute_reply.started":"2024-06-21T12:35:30.374734Z","shell.execute_reply":"2024-06-21T12:35:58.207651Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-06-21 12:35:40.549380: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-21 12:35:40.549481: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-21 12:35:40.793916: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:35:58.209936Z","iopub.execute_input":"2024-06-21T12:35:58.210473Z","iopub.status.idle":"2024-06-21T12:35:58.266839Z","shell.execute_reply.started":"2024-06-21T12:35:58.210445Z","shell.execute_reply":"2024-06-21T12:35:58.265715Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"PATH = '/kaggle/input/cleaned-data/cleaned_data.csv'\ndf_org= pd.read_csv(PATH)\ndf_org","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:35:58.268292Z","iopub.execute_input":"2024-06-21T12:35:58.269153Z","iopub.status.idle":"2024-06-21T12:35:58.387227Z","shell.execute_reply.started":"2024-06-21T12:35:58.269118Z","shell.execute_reply":"2024-06-21T12:35:58.386236Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                           Label                                    Name\n0                  ghế_văn_phòng                                  ghế hq\n1                      thước_dây  thước dây làm bằng sợi thủy tinh total\n2                        cưa_tay         cưa gỗ cầm tay cán lớn asaki ak\n3                       váy,_đầm           đầm ren cổ v tay ngắn cao cấp\n4      dụng_cụ_đo,_kiểm_tra_khác             máy đo độ đồng tâm hann yan\n...                          ...                                     ...\n14971          máy_làm_lạnh_nước                 máy làm lạnh nước orion\n14972         bàn_ghế_trang_điểm                            bàn phấn mdf\n14973                   bàn_phím                          bàn phím rapoo\n14974                     sàn_gỗ                        sàn gỗ morser ly\n14975  thiết_bị_đo,_kiểm_tra_khí             máy đo khí cố định senko si\n\n[14976 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ghế_văn_phòng</td>\n      <td>ghế hq</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>thước_dây</td>\n      <td>thước dây làm bằng sợi thủy tinh total</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cưa_tay</td>\n      <td>cưa gỗ cầm tay cán lớn asaki ak</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>váy,_đầm</td>\n      <td>đầm ren cổ v tay ngắn cao cấp</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dụng_cụ_đo,_kiểm_tra_khác</td>\n      <td>máy đo độ đồng tâm hann yan</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14971</th>\n      <td>máy_làm_lạnh_nước</td>\n      <td>máy làm lạnh nước orion</td>\n    </tr>\n    <tr>\n      <th>14972</th>\n      <td>bàn_ghế_trang_điểm</td>\n      <td>bàn phấn mdf</td>\n    </tr>\n    <tr>\n      <th>14973</th>\n      <td>bàn_phím</td>\n      <td>bàn phím rapoo</td>\n    </tr>\n    <tr>\n      <th>14974</th>\n      <td>sàn_gỗ</td>\n      <td>sàn gỗ morser ly</td>\n    </tr>\n    <tr>\n      <th>14975</th>\n      <td>thiết_bị_đo,_kiểm_tra_khí</td>\n      <td>máy đo khí cố định senko si</td>\n    </tr>\n  </tbody>\n</table>\n<p>14976 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"labels = df_org['Label'].unique().tolist()\nlabels = [s.strip() for s in labels ]\nlabels[:5]","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:35:58.390414Z","iopub.execute_input":"2024-06-21T12:35:58.390697Z","iopub.status.idle":"2024-06-21T12:35:58.402660Z","shell.execute_reply.started":"2024-06-21T12:35:58.390673Z","shell.execute_reply":"2024-06-21T12:35:58.401727Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['ghế_văn_phòng',\n 'thước_dây',\n 'cưa_tay',\n 'váy,_đầm',\n 'dụng_cụ_đo,_kiểm_tra_khác']"},"metadata":{}}]},{"cell_type":"code","source":"NUM_LABELS= len(labels)\n\nid2label={id:label for id,label in enumerate(labels)}\n\nlabel2id={label:id for id,label in enumerate(labels)}","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:35:58.403943Z","iopub.execute_input":"2024-06-21T12:35:58.404317Z","iopub.status.idle":"2024-06-21T12:35:58.414737Z","shell.execute_reply.started":"2024-06-21T12:35:58.404284Z","shell.execute_reply":"2024-06-21T12:35:58.413873Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#label2id\n#id2label","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:35:58.415785Z","iopub.execute_input":"2024-06-21T12:35:58.416037Z","iopub.status.idle":"2024-06-21T12:35:58.426272Z","shell.execute_reply.started":"2024-06-21T12:35:58.416014Z","shell.execute_reply":"2024-06-21T12:35:58.425558Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df_org[\"labels\"]=df_org.Label.map(lambda x: label2id[x.strip()])","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:35:58.427309Z","iopub.execute_input":"2024-06-21T12:35:58.427570Z","iopub.status.idle":"2024-06-21T12:35:58.449064Z","shell.execute_reply.started":"2024-06-21T12:35:58.427546Z","shell.execute_reply":"2024-06-21T12:35:58.448310Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df_org.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:35:58.450036Z","iopub.execute_input":"2024-06-21T12:35:58.450336Z","iopub.status.idle":"2024-06-21T12:35:58.465740Z","shell.execute_reply.started":"2024-06-21T12:35:58.450312Z","shell.execute_reply":"2024-06-21T12:35:58.464773Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                       Label                                    Name  labels\n0              ghế_văn_phòng                                  ghế hq       0\n1                  thước_dây  thước dây làm bằng sợi thủy tinh total       1\n2                    cưa_tay         cưa gỗ cầm tay cán lớn asaki ak       2\n3                   váy,_đầm           đầm ren cổ v tay ngắn cao cấp       3\n4  dụng_cụ_đo,_kiểm_tra_khác             máy đo độ đồng tâm hann yan       4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Name</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ghế_văn_phòng</td>\n      <td>ghế hq</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>thước_dây</td>\n      <td>thước dây làm bằng sợi thủy tinh total</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cưa_tay</td>\n      <td>cưa gỗ cầm tay cán lớn asaki ak</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>váy,_đầm</td>\n      <td>đầm ren cổ v tay ngắn cao cấp</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dụng_cụ_đo,_kiểm_tra_khác</td>\n      <td>máy đo độ đồng tâm hann yan</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Giả sử df_org đã được định nghĩa\nSIZE = df_org.shape[0]\n\n# Tính toán số lượng mẫu cho từng tập\ntrain_size = int(0.7 * SIZE)\nval_size = int(0.15 * SIZE)\ntest_size = SIZE - train_size - val_size  # Cái này sẽ đảm bảo đủ 100%\n\n# Chia dữ liệu\ntrain_texts = list(df_org.Name[:train_size])\nval_texts = list(df_org.Name[train_size:train_size + val_size])\ntest_texts = list(df_org.Name[train_size + val_size:])\n\ntrain_labels = list(df_org.labels[:train_size])\nval_labels = list(df_org.labels[train_size:train_size + val_size])\ntest_labels = list(df_org.labels[train_size + val_size:])","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:35:58.466948Z","iopub.execute_input":"2024-06-21T12:35:58.467670Z","iopub.status.idle":"2024-06-21T12:35:58.487945Z","shell.execute_reply.started":"2024-06-21T12:35:58.467644Z","shell.execute_reply":"2024-06-21T12:35:58.486901Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"len(train_texts), len(val_texts), len(test_texts)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:35:58.489251Z","iopub.execute_input":"2024-06-21T12:35:58.489546Z","iopub.status.idle":"2024-06-21T12:35:58.501224Z","shell.execute_reply.started":"2024-06-21T12:35:58.489521Z","shell.execute_reply":"2024-06-21T12:35:58.500216Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(10483, 2246, 2247)"},"metadata":{}}]},{"cell_type":"code","source":"# Kiểm tra và in loại dữ liệu của các phần tử trong danh sách\nprint(type(train_texts[0]))  # Phải là <class 'str'>\nprint(type(val_texts[0]))    # Phải là <class 'str'>\nprint(type(test_texts[0]))   # Phải là <class 'str'>","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:35:58.502497Z","iopub.execute_input":"2024-06-21T12:35:58.502823Z","iopub.status.idle":"2024-06-21T12:35:58.511467Z","shell.execute_reply.started":"2024-06-21T12:35:58.502797Z","shell.execute_reply":"2024-06-21T12:35:58.510524Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"<class 'str'>\n<class 'str'>\n<class 'str'>\n","output_type":"stream"}]},{"cell_type":"code","source":"# Tải mô hình và tokenizer\nmodel = RobertaForSequenceClassification.from_pretrained(\"wonrax/phobert-base-vietnamese-sentiment\", num_labels=NUM_LABELS, id2label=id2label, label2id=label2id, ignore_mismatched_sizes=True)\ntokenizer = AutoTokenizer.from_pretrained(\"wonrax/phobert-base-vietnamese-sentiment\", use_fast=False, max_length=30)\n# Chuyển model sang thiết bị (CPU/GPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:35:58.512698Z","iopub.execute_input":"2024-06-21T12:35:58.512997Z","iopub.status.idle":"2024-06-21T12:36:05.668196Z","shell.execute_reply.started":"2024-06-21T12:35:58.512971Z","shell.execute_reply":"2024-06-21T12:36:05.667276Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/999 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fc35ee482f948e4a1989f95b198a8cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6924b6a1b0234c82a2d9378ada3a2d23"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at wonrax/phobert-base-vietnamese-sentiment and are newly initialized because the shapes did not match:\n- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([1971, 768]) in the model instantiated\n- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([1971]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ba2a4fb166a4faca5f3aad34504c81b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f7907fb28de454f96c2a021871dfaed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"406736c437cb4e639f3cd31d670f4572"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/17.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35f44ca56a0d4407a41e202184576f20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40c67415422e44e9aca6d260779aaae8"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n      (position_embeddings): Embedding(258, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=1971, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Kiểm tra các phần tử không phải chuỗi\nnon_str_elements = [text for text in train_texts if not isinstance(text, str)]\nprint(\"Các phần tử không phải chuỗi trong train_texts:\", non_str_elements)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:36:05.673103Z","iopub.execute_input":"2024-06-21T12:36:05.673402Z","iopub.status.idle":"2024-06-21T12:36:05.679897Z","shell.execute_reply.started":"2024-06-21T12:36:05.673378Z","shell.execute_reply":"2024-06-21T12:36:05.678862Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Các phần tử không phải chuỗi trong train_texts: [nan, nan, nan]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Hàm để lọc bỏ các giá trị NaN\ndef filter_nan(texts, labels):\n    filtered_texts = []\n    filtered_labels = []\n    for text, label in zip(texts, labels):\n        if pd.notna(text):\n            filtered_texts.append(text)\n            filtered_labels.append(label)\n    return filtered_texts, filtered_labels\n\n# Lọc bỏ các giá trị NaN\ntrain_texts, train_labels = filter_nan(train_texts, train_labels)\nval_texts, val_labels = filter_nan(val_texts, val_labels)\ntest_texts, test_labels = filter_nan(test_texts, test_labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:36:05.681191Z","iopub.execute_input":"2024-06-21T12:36:05.681483Z","iopub.status.idle":"2024-06-21T12:36:05.842290Z","shell.execute_reply.started":"2024-06-21T12:36:05.681460Z","shell.execute_reply":"2024-06-21T12:36:05.841451Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"len(test_texts), len(test_labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:36:05.843634Z","iopub.execute_input":"2024-06-21T12:36:05.844464Z","iopub.status.idle":"2024-06-21T12:36:05.859329Z","shell.execute_reply.started":"2024-06-21T12:36:05.844430Z","shell.execute_reply":"2024-06-21T12:36:05.858400Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(2247, 2247)"},"metadata":{}}]},{"cell_type":"code","source":"# Check the data type of each element after filtering\nassert all(isinstance(text, str) for text in train_texts), \"Train texts contain elements that are not strings\"\nassert all(isinstance(text, str) for text in val_texts), \"Val texts contain elements that are not strings\"\nassert all(isinstance(text, str) for text in test_texts), \"Test texts contain elements that are not strings\"","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:36:05.860717Z","iopub.execute_input":"2024-06-21T12:36:05.861097Z","iopub.status.idle":"2024-06-21T12:36:05.870014Z","shell.execute_reply.started":"2024-06-21T12:36:05.861045Z","shell.execute_reply":"2024-06-21T12:36:05.869095Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Tokenizer\ntrain_encodings = tokenizer(train_texts, truncation=True, padding=True)\nval_encodings = tokenizer(val_texts, truncation=True, padding=True)\ntest_encodings = tokenizer(test_texts, truncation=True, padding=True)\n\n# Length check\nprint(len(train_texts), len(val_texts), len(test_texts))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:36:05.871524Z","iopub.execute_input":"2024-06-21T12:36:05.872241Z","iopub.status.idle":"2024-06-21T12:36:07.583440Z","shell.execute_reply.started":"2024-06-21T12:36:05.872207Z","shell.execute_reply":"2024-06-21T12:36:07.582504Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"10480 2246 2247\n","output_type":"stream"}]},{"cell_type":"code","source":"class DataLoader(Dataset):\n    \"\"\"\n    Custom Dataset class for handling tokenized text data and corresponding labels.\n    Inherits from torch.utils.data.Dataset.\n    \"\"\"\n    def __init__(self, encodings, labels):\n        \"\"\"\n        Initializes the DataLoader class with encodings and labels.\n\n        Args:\n            encodings (dict): A dictionary containing tokenized input text data\n                              (e.g., 'input_ids', 'token_type_ids', 'attention_mask').\n            labels (list): A list of integer labels for the input text data.\n        \"\"\"\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Returns a dictionary containing tokenized data and the corresponding label for a given index.\n\n        Args:\n            idx (int): The index of the data item to retrieve.\n\n        Returns:\n            item (dict): A dictionary containing the tokenized data and the corresponding label.\n        \"\"\"\n        # Retrieve tokenized data for the given index\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        # Add the label for the given index to the item dictionary\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        \"\"\"\n        Returns the number of data items in the dataset.\n\n        Returns:\n            (int): The number of data items in the dataset.\n        \"\"\"\n        return len(self.labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:36:07.591388Z","iopub.execute_input":"2024-06-21T12:36:07.591728Z","iopub.status.idle":"2024-06-21T12:36:07.601345Z","shell.execute_reply.started":"2024-06-21T12:36:07.591696Z","shell.execute_reply":"2024-06-21T12:36:07.600575Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_encodings, train_labels)\n\nval_dataloader = DataLoader(val_encodings, val_labels)\n\ntest_dataset = DataLoader(test_encodings, test_labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:36:07.602399Z","iopub.execute_input":"2024-06-21T12:36:07.602786Z","iopub.status.idle":"2024-06-21T12:36:07.617211Z","shell.execute_reply.started":"2024-06-21T12:36:07.602751Z","shell.execute_reply":"2024-06-21T12:36:07.616561Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\ndef compute_metrics(pred):\n    # Extract true labels from the input object\n    labels = pred.label_ids\n    \n    # Obtain predicted class labels by finding the column index with the maximum probability\n    preds = pred.predictions.argmax(-1)\n    \n    # Compute macro precision, recall, and F1 score using sklearn's precision_recall_fscore_support function\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n    \n    # Calculate the accuracy score using sklearn's accuracy_score function\n    acc = accuracy_score(labels, preds)\n    \n    # Return the computed metrics as a dictionary\n    return {\n        'Accuracy': acc,\n        'F1': f1,\n        'Precision': precision,\n        'Recall': recall\n    }","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:36:07.618377Z","iopub.execute_input":"2024-06-21T12:36:07.618738Z","iopub.status.idle":"2024-06-21T12:36:08.390245Z","shell.execute_reply.started":"2024-06-21T12:36:07.618704Z","shell.execute_reply":"2024-06-21T12:36:08.389197Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import warnings\nfrom sklearn.exceptions import UndefinedMetricWarning\n\nwarnings.filterwarnings(\"ignore\", message=\"Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\")\nwarnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:36:08.391635Z","iopub.execute_input":"2024-06-21T12:36:08.392448Z","iopub.status.idle":"2024-06-21T12:36:08.398473Z","shell.execute_reply.started":"2024-06-21T12:36:08.392409Z","shell.execute_reply":"2024-06-21T12:36:08.397557Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    # The output directory where the model predictions and checkpoints will be written\n    output_dir='./pho-bert-classification', \n    do_train=True,\n    do_eval=True,\n    # The number of epochs, defaults to 3.0 \n    num_train_epochs=100,              \n    per_device_train_batch_size=16,  \n    per_device_eval_batch_size=32,\n    # Number of steps used for a linear warmup\n    warmup_steps=100,                \n    weight_decay=0.01,\n    logging_strategy='steps',\n    # TensorBoard log directory                 \n    logging_dir='./multi-class-logs',            \n    logging_steps=500,  \n    evaluation_strategy=\"steps\",\n    eval_steps=500,\n    save_strategy=\"steps\", \n    save_steps=1000,  \n    save_total_limit=2,  \n    fp16=True,\n    load_best_model_at_end=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:36:08.399754Z","iopub.execute_input":"2024-06-21T12:36:08.400121Z","iopub.status.idle":"2024-06-21T12:36:08.441752Z","shell.execute_reply.started":"2024-06-21T12:36:08.400071Z","shell.execute_reply":"2024-06-21T12:36:08.440873Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Trainer(\n    # the pre-trained model that will be fine-tuned \n    model=model,\n     # training arguments that we defined above                        \n    args=training_args,                 \n    train_dataset=train_dataloader,         \n    eval_dataset=val_dataloader,            \n    compute_metrics= compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:36:08.442976Z","iopub.execute_input":"2024-06-21T12:36:08.443300Z","iopub.status.idle":"2024-06-21T12:36:09.630911Z","shell.execute_reply.started":"2024-06-21T12:36:08.443274Z","shell.execute_reply":"2024-06-21T12:36:09.629930Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:36:09.632378Z","iopub.execute_input":"2024-06-21T12:36:09.633098Z","iopub.status.idle":"2024-06-21T15:14:11.536239Z","shell.execute_reply.started":"2024-06-21T12:36:09.633040Z","shell.execute_reply":"2024-06-21T15:14:11.535448Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240621_124020-k18h1ybg</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/vuzle/huggingface/runs/k18h1ybg' target=\"_blank\">./pho-bert-classification</a></strong> to <a href='https://wandb.ai/vuzle/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/vuzle/huggingface' target=\"_blank\">https://wandb.ai/vuzle/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/vuzle/huggingface/runs/k18h1ybg' target=\"_blank\">https://wandb.ai/vuzle/huggingface/runs/k18h1ybg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='32800' max='32800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [32800/32800 2:33:29, Epoch 100/100]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>6.624400</td>\n      <td>5.730442</td>\n      <td>0.156723</td>\n      <td>0.011091</td>\n      <td>0.009311</td>\n      <td>0.022810</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>5.017100</td>\n      <td>4.512115</td>\n      <td>0.328584</td>\n      <td>0.065537</td>\n      <td>0.057773</td>\n      <td>0.096725</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>3.816100</td>\n      <td>3.689478</td>\n      <td>0.459484</td>\n      <td>0.148562</td>\n      <td>0.136974</td>\n      <td>0.192087</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>2.999000</td>\n      <td>3.226604</td>\n      <td>0.512912</td>\n      <td>0.196123</td>\n      <td>0.184316</td>\n      <td>0.245165</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>2.341000</td>\n      <td>2.872236</td>\n      <td>0.568121</td>\n      <td>0.251142</td>\n      <td>0.237330</td>\n      <td>0.305103</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.885200</td>\n      <td>2.639239</td>\n      <td>0.605521</td>\n      <td>0.289429</td>\n      <td>0.274837</td>\n      <td>0.341353</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>1.494000</td>\n      <td>2.512645</td>\n      <td>0.621995</td>\n      <td>0.321270</td>\n      <td>0.309403</td>\n      <td>0.366959</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>1.191100</td>\n      <td>2.432720</td>\n      <td>0.637578</td>\n      <td>0.351082</td>\n      <td>0.343410</td>\n      <td>0.394595</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.957800</td>\n      <td>2.377387</td>\n      <td>0.650490</td>\n      <td>0.365188</td>\n      <td>0.358593</td>\n      <td>0.405119</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.774300</td>\n      <td>2.355080</td>\n      <td>0.653606</td>\n      <td>0.380818</td>\n      <td>0.375980</td>\n      <td>0.419496</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.607800</td>\n      <td>2.340191</td>\n      <td>0.674533</td>\n      <td>0.399124</td>\n      <td>0.394028</td>\n      <td>0.437628</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.493500</td>\n      <td>2.329961</td>\n      <td>0.673197</td>\n      <td>0.403006</td>\n      <td>0.402432</td>\n      <td>0.434600</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.403400</td>\n      <td>2.319830</td>\n      <td>0.684773</td>\n      <td>0.414478</td>\n      <td>0.412980</td>\n      <td>0.447977</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.322100</td>\n      <td>2.319848</td>\n      <td>0.679875</td>\n      <td>0.418374</td>\n      <td>0.416463</td>\n      <td>0.448993</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.252600</td>\n      <td>2.357735</td>\n      <td>0.687444</td>\n      <td>0.424847</td>\n      <td>0.425133</td>\n      <td>0.453171</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.208500</td>\n      <td>2.340621</td>\n      <td>0.691006</td>\n      <td>0.425872</td>\n      <td>0.427338</td>\n      <td>0.453505</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>0.168300</td>\n      <td>2.374788</td>\n      <td>0.688335</td>\n      <td>0.427283</td>\n      <td>0.430242</td>\n      <td>0.453087</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.127400</td>\n      <td>2.427585</td>\n      <td>0.687890</td>\n      <td>0.423180</td>\n      <td>0.428383</td>\n      <td>0.446655</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>0.105800</td>\n      <td>2.452498</td>\n      <td>0.685663</td>\n      <td>0.424643</td>\n      <td>0.429796</td>\n      <td>0.448579</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.085900</td>\n      <td>2.482303</td>\n      <td>0.689225</td>\n      <td>0.427929</td>\n      <td>0.433341</td>\n      <td>0.449189</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>0.069100</td>\n      <td>2.491787</td>\n      <td>0.693678</td>\n      <td>0.426636</td>\n      <td>0.431878</td>\n      <td>0.448554</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>0.054600</td>\n      <td>2.543532</td>\n      <td>0.689671</td>\n      <td>0.421661</td>\n      <td>0.427924</td>\n      <td>0.442892</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>0.045000</td>\n      <td>2.590792</td>\n      <td>0.690116</td>\n      <td>0.423950</td>\n      <td>0.430611</td>\n      <td>0.445818</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>0.037200</td>\n      <td>2.637759</td>\n      <td>0.691006</td>\n      <td>0.422084</td>\n      <td>0.428108</td>\n      <td>0.442235</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>0.034600</td>\n      <td>2.686066</td>\n      <td>0.690116</td>\n      <td>0.424299</td>\n      <td>0.432404</td>\n      <td>0.444610</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>0.025400</td>\n      <td>2.738524</td>\n      <td>0.690116</td>\n      <td>0.421660</td>\n      <td>0.427158</td>\n      <td>0.443502</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>0.025500</td>\n      <td>2.765726</td>\n      <td>0.688780</td>\n      <td>0.420427</td>\n      <td>0.424736</td>\n      <td>0.442465</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>0.023400</td>\n      <td>2.836906</td>\n      <td>0.693232</td>\n      <td>0.427351</td>\n      <td>0.433373</td>\n      <td>0.446940</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>0.022200</td>\n      <td>2.864430</td>\n      <td>0.691451</td>\n      <td>0.420877</td>\n      <td>0.429669</td>\n      <td>0.439838</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>0.019400</td>\n      <td>2.885789</td>\n      <td>0.690561</td>\n      <td>0.421908</td>\n      <td>0.430060</td>\n      <td>0.441315</td>\n    </tr>\n    <tr>\n      <td>15500</td>\n      <td>0.018400</td>\n      <td>2.972611</td>\n      <td>0.689671</td>\n      <td>0.423512</td>\n      <td>0.429048</td>\n      <td>0.446786</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>0.021300</td>\n      <td>2.982111</td>\n      <td>0.695904</td>\n      <td>0.433140</td>\n      <td>0.438865</td>\n      <td>0.454709</td>\n    </tr>\n    <tr>\n      <td>16500</td>\n      <td>0.017100</td>\n      <td>3.003730</td>\n      <td>0.694568</td>\n      <td>0.430958</td>\n      <td>0.436845</td>\n      <td>0.451978</td>\n    </tr>\n    <tr>\n      <td>17000</td>\n      <td>0.020200</td>\n      <td>3.093112</td>\n      <td>0.695459</td>\n      <td>0.429026</td>\n      <td>0.434122</td>\n      <td>0.450050</td>\n    </tr>\n    <tr>\n      <td>17500</td>\n      <td>0.018700</td>\n      <td>3.164078</td>\n      <td>0.693678</td>\n      <td>0.428294</td>\n      <td>0.435932</td>\n      <td>0.447337</td>\n    </tr>\n    <tr>\n      <td>18000</td>\n      <td>0.018300</td>\n      <td>3.179722</td>\n      <td>0.689225</td>\n      <td>0.422728</td>\n      <td>0.430477</td>\n      <td>0.442881</td>\n    </tr>\n    <tr>\n      <td>18500</td>\n      <td>0.018400</td>\n      <td>3.198460</td>\n      <td>0.691451</td>\n      <td>0.426923</td>\n      <td>0.432689</td>\n      <td>0.446420</td>\n    </tr>\n    <tr>\n      <td>19000</td>\n      <td>0.018600</td>\n      <td>3.266672</td>\n      <td>0.696794</td>\n      <td>0.431457</td>\n      <td>0.438345</td>\n      <td>0.452336</td>\n    </tr>\n    <tr>\n      <td>19500</td>\n      <td>0.020200</td>\n      <td>3.306800</td>\n      <td>0.695904</td>\n      <td>0.430393</td>\n      <td>0.437489</td>\n      <td>0.449885</td>\n    </tr>\n    <tr>\n      <td>20000</td>\n      <td>0.019600</td>\n      <td>3.361522</td>\n      <td>0.692787</td>\n      <td>0.429152</td>\n      <td>0.437409</td>\n      <td>0.448473</td>\n    </tr>\n    <tr>\n      <td>20500</td>\n      <td>0.020100</td>\n      <td>3.359247</td>\n      <td>0.696349</td>\n      <td>0.431094</td>\n      <td>0.438089</td>\n      <td>0.452168</td>\n    </tr>\n    <tr>\n      <td>21000</td>\n      <td>0.020800</td>\n      <td>3.381071</td>\n      <td>0.699466</td>\n      <td>0.435792</td>\n      <td>0.442398</td>\n      <td>0.455961</td>\n    </tr>\n    <tr>\n      <td>21500</td>\n      <td>0.018800</td>\n      <td>3.459439</td>\n      <td>0.698575</td>\n      <td>0.433676</td>\n      <td>0.441454</td>\n      <td>0.453367</td>\n    </tr>\n    <tr>\n      <td>22000</td>\n      <td>0.022000</td>\n      <td>3.484994</td>\n      <td>0.697685</td>\n      <td>0.431853</td>\n      <td>0.438664</td>\n      <td>0.452318</td>\n    </tr>\n    <tr>\n      <td>22500</td>\n      <td>0.020300</td>\n      <td>3.539322</td>\n      <td>0.695904</td>\n      <td>0.432808</td>\n      <td>0.440255</td>\n      <td>0.453194</td>\n    </tr>\n    <tr>\n      <td>23000</td>\n      <td>0.021200</td>\n      <td>3.534892</td>\n      <td>0.700356</td>\n      <td>0.435108</td>\n      <td>0.442196</td>\n      <td>0.454508</td>\n    </tr>\n    <tr>\n      <td>23500</td>\n      <td>0.021600</td>\n      <td>3.585099</td>\n      <td>0.695013</td>\n      <td>0.426611</td>\n      <td>0.434436</td>\n      <td>0.446014</td>\n    </tr>\n    <tr>\n      <td>24000</td>\n      <td>0.021400</td>\n      <td>3.615125</td>\n      <td>0.698130</td>\n      <td>0.430570</td>\n      <td>0.436777</td>\n      <td>0.451559</td>\n    </tr>\n    <tr>\n      <td>24500</td>\n      <td>0.020500</td>\n      <td>3.641884</td>\n      <td>0.699020</td>\n      <td>0.431928</td>\n      <td>0.438519</td>\n      <td>0.452266</td>\n    </tr>\n    <tr>\n      <td>25000</td>\n      <td>0.023800</td>\n      <td>3.673930</td>\n      <td>0.697685</td>\n      <td>0.429844</td>\n      <td>0.436814</td>\n      <td>0.450221</td>\n    </tr>\n    <tr>\n      <td>25500</td>\n      <td>0.022800</td>\n      <td>3.694482</td>\n      <td>0.695904</td>\n      <td>0.429324</td>\n      <td>0.436100</td>\n      <td>0.449303</td>\n    </tr>\n    <tr>\n      <td>26000</td>\n      <td>0.019800</td>\n      <td>3.728191</td>\n      <td>0.698130</td>\n      <td>0.432683</td>\n      <td>0.438531</td>\n      <td>0.453950</td>\n    </tr>\n    <tr>\n      <td>26500</td>\n      <td>0.025100</td>\n      <td>3.728171</td>\n      <td>0.699466</td>\n      <td>0.433799</td>\n      <td>0.441073</td>\n      <td>0.454818</td>\n    </tr>\n    <tr>\n      <td>27000</td>\n      <td>0.022200</td>\n      <td>3.752448</td>\n      <td>0.697240</td>\n      <td>0.429762</td>\n      <td>0.435202</td>\n      <td>0.450702</td>\n    </tr>\n    <tr>\n      <td>27500</td>\n      <td>0.021200</td>\n      <td>3.789192</td>\n      <td>0.694568</td>\n      <td>0.427378</td>\n      <td>0.434974</td>\n      <td>0.447178</td>\n    </tr>\n    <tr>\n      <td>28000</td>\n      <td>0.021900</td>\n      <td>3.796348</td>\n      <td>0.695904</td>\n      <td>0.433583</td>\n      <td>0.441512</td>\n      <td>0.453236</td>\n    </tr>\n    <tr>\n      <td>28500</td>\n      <td>0.024300</td>\n      <td>3.811599</td>\n      <td>0.697240</td>\n      <td>0.429515</td>\n      <td>0.436457</td>\n      <td>0.449495</td>\n    </tr>\n    <tr>\n      <td>29000</td>\n      <td>0.024000</td>\n      <td>3.824587</td>\n      <td>0.696349</td>\n      <td>0.427246</td>\n      <td>0.433931</td>\n      <td>0.447285</td>\n    </tr>\n    <tr>\n      <td>29500</td>\n      <td>0.021200</td>\n      <td>3.828209</td>\n      <td>0.695013</td>\n      <td>0.427002</td>\n      <td>0.434583</td>\n      <td>0.446766</td>\n    </tr>\n    <tr>\n      <td>30000</td>\n      <td>0.023700</td>\n      <td>3.854223</td>\n      <td>0.697685</td>\n      <td>0.434065</td>\n      <td>0.441092</td>\n      <td>0.454903</td>\n    </tr>\n    <tr>\n      <td>30500</td>\n      <td>0.022600</td>\n      <td>3.858335</td>\n      <td>0.698130</td>\n      <td>0.431581</td>\n      <td>0.438737</td>\n      <td>0.452009</td>\n    </tr>\n    <tr>\n      <td>31000</td>\n      <td>0.023800</td>\n      <td>3.870136</td>\n      <td>0.698575</td>\n      <td>0.434653</td>\n      <td>0.441662</td>\n      <td>0.455157</td>\n    </tr>\n    <tr>\n      <td>31500</td>\n      <td>0.022000</td>\n      <td>3.872075</td>\n      <td>0.696349</td>\n      <td>0.430393</td>\n      <td>0.437213</td>\n      <td>0.451488</td>\n    </tr>\n    <tr>\n      <td>32000</td>\n      <td>0.022400</td>\n      <td>3.879065</td>\n      <td>0.696349</td>\n      <td>0.429929</td>\n      <td>0.436938</td>\n      <td>0.450203</td>\n    </tr>\n    <tr>\n      <td>32500</td>\n      <td>0.021600</td>\n      <td>3.880594</td>\n      <td>0.696794</td>\n      <td>0.430456</td>\n      <td>0.437087</td>\n      <td>0.451580</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=32800, training_loss=0.47234468554578174, metrics={'train_runtime': 9481.5561, 'train_samples_per_second': 110.53, 'train_steps_per_second': 3.459, 'total_flos': 2.0826906460704e+16, 'train_loss': 0.47234468554578174, 'epoch': 100.0})"},"metadata":{}}]},{"cell_type":"code","source":"q=[trainer.evaluate(eval_dataset=df_org) for df_org in [train_dataloader, val_dataloader, test_dataset]]\n\npd.DataFrame(q, index=[\"train\",\"val\",\"test\"]).iloc[:,:5]","metadata":{"execution":{"iopub.status.busy":"2024-06-21T16:01:46.906274Z","iopub.execute_input":"2024-06-21T16:01:46.907080Z","iopub.status.idle":"2024-06-21T16:02:13.047535Z","shell.execute_reply.started":"2024-06-21T16:01:46.907037Z","shell.execute_reply":"2024-06-21T16:02:13.046473Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"       eval_loss  eval_Accuracy   eval_F1  eval_Precision  eval_Recall\ntrain   0.210958       0.982156  0.929723        0.926232     0.937418\nval     2.319848       0.679875  0.418374        0.416463     0.448993\ntest    2.190387       0.684913  0.440927        0.441439     0.471791","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eval_loss</th>\n      <th>eval_Accuracy</th>\n      <th>eval_F1</th>\n      <th>eval_Precision</th>\n      <th>eval_Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>train</th>\n      <td>0.210958</td>\n      <td>0.982156</td>\n      <td>0.929723</td>\n      <td>0.926232</td>\n      <td>0.937418</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>2.319848</td>\n      <td>0.679875</td>\n      <td>0.418374</td>\n      <td>0.416463</td>\n      <td>0.448993</td>\n    </tr>\n    <tr>\n      <th>test</th>\n      <td>2.190387</td>\n      <td>0.684913</td>\n      <td>0.440927</td>\n      <td>0.441439</td>\n      <td>0.471791</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def predict(text):\n    \"\"\"\n    Predicts the class label for a given input text\n\n    Args:\n        text (str): The input text for which the class label needs to be predicted.\n\n    Returns:\n        probs (torch.Tensor): Class probabilities for the input text.\n        pred_label_idx (torch.Tensor): The index of the predicted class label.\n        pred_label (str): The predicted class label.\n    \"\"\"\n    # Tokenize the input text and move tensors to the GPU if available\n    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(\"cuda\")\n\n    # Get model output (logits)\n    outputs = model(**inputs)\n\n    probs = outputs[0].softmax(1)\n    \"\"\" Explanation outputs: The BERT model returns a tuple containing the output logits (and possibly other elements depending on the model configuration). In this case, the output logits are the first element in the tuple, which is why we access it using outputs[0].\n\n    outputs[0]: This is a tensor containing the raw output logits for each class. The shape of the tensor is (batch_size, num_classes) where batch_size is the number of input samples (in this case, 1, as we are predicting for a single input text) and num_classes is the number of target classes.\n\n    softmax(1): The softmax function is applied along dimension 1 (the class dimension) to convert the raw logits into class probabilities. Softmax normalizes the logits so that they sum to 1, making them interpretable as probabilities. \"\"\"\n\n    # Get the index of the class with the highest probability\n    # argmax() finds the index of the maximum value in the tensor along a specified dimension.\n    # By default, if no dimension is specified, it returns the index of the maximum value in the flattened tensor.\n    pred_label_idx = probs.argmax()\n\n    # Now map the predicted class index to the actual class label \n    # Since pred_label_idx is a tensor containing a single value (the predicted class index), \n    # the .item() method is used to extract the value as a scalar\n    pred_label = model.config.id2label[pred_label_idx.item()]\n\n    return probs, pred_label_idx, pred_label","metadata":{"execution":{"iopub.status.busy":"2024-06-21T15:14:37.324739Z","iopub.execute_input":"2024-06-21T15:14:37.325037Z","iopub.status.idle":"2024-06-21T15:14:37.335904Z","shell.execute_reply.started":"2024-06-21T15:14:37.325012Z","shell.execute_reply":"2024-06-21T15:14:37.334894Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Test with a an example text in Turkish\ntext = \"ghế hq\"\n# \"Machine Learning itself is moving towards more and more automated\"\npredict(text)[2]","metadata":{"execution":{"iopub.status.busy":"2024-06-21T15:14:37.337362Z","iopub.execute_input":"2024-06-21T15:14:37.337879Z","iopub.status.idle":"2024-06-21T15:14:37.489317Z","shell.execute_reply.started":"2024-06-21T15:14:37.337688Z","shell.execute_reply":"2024-06-21T15:14:37.488377Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"'ghế_văn_phòng'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Save model for inference","metadata":{}},{"cell_type":"code","source":"model_path = \"pho-bert-classification\"\ntrainer.save_model(model_path)\ntokenizer.save_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T15:14:37.490412Z","iopub.execute_input":"2024-06-21T15:14:37.490666Z","iopub.status.idle":"2024-06-21T15:14:38.665734Z","shell.execute_reply.started":"2024-06-21T15:14:37.490642Z","shell.execute_reply":"2024-06-21T15:14:38.664542Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"('pho-bert-classification/tokenizer_config.json',\n 'pho-bert-classification/special_tokens_map.json',\n 'pho-bert-classification/vocab.txt',\n 'pho-bert-classification/bpe.codes',\n 'pho-bert-classification/added_tokens.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Re-Load saved model for inference","metadata":{}},{"cell_type":"code","source":"model_path = \"pho-bert-classification\"","metadata":{"execution":{"iopub.status.busy":"2024-06-21T15:14:38.667144Z","iopub.execute_input":"2024-06-21T15:14:38.667435Z","iopub.status.idle":"2024-06-21T15:14:38.672220Z","shell.execute_reply.started":"2024-06-21T15:14:38.667411Z","shell.execute_reply":"2024-06-21T15:14:38.671380Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Load model and tokenizer\nmodel = RobertaForSequenceClassification.from_pretrained(\"wonrax/phobert-base-vietnamese-sentiment\", num_labels=NUM_LABELS, id2label=id2label, label2id=label2id, ignore_mismatched_sizes=True)\ntokenizer = AutoTokenizer.from_pretrained(\"wonrax/phobert-base-vietnamese-sentiment\", use_fast=False, max_length=30)\n# Switch model to device (CPU/GPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T15:14:38.673323Z","iopub.execute_input":"2024-06-21T15:14:38.673586Z","iopub.status.idle":"2024-06-21T15:14:40.947130Z","shell.execute_reply.started":"2024-06-21T15:14:38.673556Z","shell.execute_reply":"2024-06-21T15:14:40.945806Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at wonrax/phobert-base-vietnamese-sentiment and are newly initialized because the shapes did not match:\n- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([1971, 768]) in the model instantiated\n- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([1971]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n      (position_embeddings): Embedding(258, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=1971, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"model = RobertaForSequenceClassification.from_pretrained(model_path)\ntokenizer= AutoTokenizer.from_pretrained(model_path)\nnlp= pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T15:14:40.948701Z","iopub.execute_input":"2024-06-21T15:14:40.949136Z","iopub.status.idle":"2024-06-21T15:14:41.703025Z","shell.execute_reply.started":"2024-06-21T15:14:40.949092Z","shell.execute_reply":"2024-06-21T15:14:41.701931Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"nlp(\"máy lọc\") ","metadata":{"execution":{"iopub.status.busy":"2024-06-21T16:08:06.002815Z","iopub.execute_input":"2024-06-21T16:08:06.003287Z","iopub.status.idle":"2024-06-21T16:08:06.060067Z","shell.execute_reply.started":"2024-06-21T16:08:06.003257Z","shell.execute_reply":"2024-06-21T16:08:06.059262Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"[{'label': 'máy_lọc_nước', 'score': 0.692017138004303}]"},"metadata":{}}]}]}